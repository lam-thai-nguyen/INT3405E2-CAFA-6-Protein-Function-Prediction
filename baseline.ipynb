{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f0769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0525bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>taxonomyID</th>\n",
       "      <th>labels</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>num_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A0C5B5G6</td>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>9606</td>\n",
       "      <td>['GO:0001649', 'GO:0033687', 'GO:0005615', 'GO...</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0JNW5</td>\n",
       "      <td>MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...</td>\n",
       "      <td>9606</td>\n",
       "      <td>['GO:0120013', 'GO:0034498', 'GO:0005769', 'GO...</td>\n",
       "      <td>1464</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0JP26</td>\n",
       "      <td>MVAEVCSMPAASAVKKPFDLRSKMGKWCHHRFPCCRGSGKSNMGTS...</td>\n",
       "      <td>9606</td>\n",
       "      <td>['GO:0005515']</td>\n",
       "      <td>581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0PK11</td>\n",
       "      <td>MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...</td>\n",
       "      <td>9606</td>\n",
       "      <td>['GO:0007605', 'GO:0005515']</td>\n",
       "      <td>232</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1A4S6</td>\n",
       "      <td>MGLQPLEFSDCYLDSPWFRERIRAHEAELERTNKFIKELIKDGKNL...</td>\n",
       "      <td>9606</td>\n",
       "      <td>['GO:0005829', 'GO:0010008', 'GO:0005515', 'GO...</td>\n",
       "      <td>786</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82399</th>\n",
       "      <td>Q9UTM1</td>\n",
       "      <td>MSKLKAQSALQKLIESQKNPNANEDGYFRRKRLAKKERPFEPKKLV...</td>\n",
       "      <td>284812</td>\n",
       "      <td>['GO:0005730']</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82400</th>\n",
       "      <td>Q9Y7I1</td>\n",
       "      <td>MSSNSNTDHSTGDNRSKSEKQTDLRNALRETESHGMPPLRGPAGFP...</td>\n",
       "      <td>284812</td>\n",
       "      <td>['GO:0005634', 'GO:0005829']</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82401</th>\n",
       "      <td>Q9Y7P7</td>\n",
       "      <td>MRSNNSSLVHCCWVSPPSLTRLPAFPSPRILSPCYCYNKRIRPFRG...</td>\n",
       "      <td>284812</td>\n",
       "      <td>['GO:0005634', 'GO:0005829']</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82402</th>\n",
       "      <td>Q9Y7Q3</td>\n",
       "      <td>MHSSRRKYNDMWTARLLIRSDQKEEKYPSFKKNAGKAINAHLIPKL...</td>\n",
       "      <td>284812</td>\n",
       "      <td>['GO:0005634', 'GO:0005739', 'GO:0005829']</td>\n",
       "      <td>149</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82403</th>\n",
       "      <td>Q9Y816</td>\n",
       "      <td>MITEFIKSFLLFFFLPFFLSMPMIFATLGEFTDDQTHHYSTLPSCD...</td>\n",
       "      <td>284812</td>\n",
       "      <td>['GO:0005737', 'GO:0005783']</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82404 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          EntryID                                           sequence  \\\n",
       "0      A0A0C5B5G6                                   MRWQEMGYIFYPRKLR   \n",
       "1          A0JNW5  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...   \n",
       "2          A0JP26  MVAEVCSMPAASAVKKPFDLRSKMGKWCHHRFPCCRGSGKSNMGTS...   \n",
       "3          A0PK11  MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...   \n",
       "4          A1A4S6  MGLQPLEFSDCYLDSPWFRERIRAHEAELERTNKFIKELIKDGKNL...   \n",
       "...           ...                                                ...   \n",
       "82399      Q9UTM1  MSKLKAQSALQKLIESQKNPNANEDGYFRRKRLAKKERPFEPKKLV...   \n",
       "82400      Q9Y7I1  MSSNSNTDHSTGDNRSKSEKQTDLRNALRETESHGMPPLRGPAGFP...   \n",
       "82401      Q9Y7P7  MRSNNSSLVHCCWVSPPSLTRLPAFPSPRILSPCYCYNKRIRPFRG...   \n",
       "82402      Q9Y7Q3  MHSSRRKYNDMWTARLLIRSDQKEEKYPSFKKNAGKAINAHLIPKL...   \n",
       "82403      Q9Y816  MITEFIKSFLLFFFLPFFLSMPMIFATLGEFTDDQTHHYSTLPSCD...   \n",
       "\n",
       "       taxonomyID                                             labels  \\\n",
       "0            9606  ['GO:0001649', 'GO:0033687', 'GO:0005615', 'GO...   \n",
       "1            9606  ['GO:0120013', 'GO:0034498', 'GO:0005769', 'GO...   \n",
       "2            9606                                     ['GO:0005515']   \n",
       "3            9606                       ['GO:0007605', 'GO:0005515']   \n",
       "4            9606  ['GO:0005829', 'GO:0010008', 'GO:0005515', 'GO...   \n",
       "...           ...                                                ...   \n",
       "82399      284812                                     ['GO:0005730']   \n",
       "82400      284812                       ['GO:0005634', 'GO:0005829']   \n",
       "82401      284812                       ['GO:0005634', 'GO:0005829']   \n",
       "82402      284812         ['GO:0005634', 'GO:0005739', 'GO:0005829']   \n",
       "82403      284812                       ['GO:0005737', 'GO:0005783']   \n",
       "\n",
       "       seq_length  num_labels  \n",
       "0              16          14  \n",
       "1            1464           8  \n",
       "2             581           1  \n",
       "3             232           2  \n",
       "4             786           5  \n",
       "...           ...         ...  \n",
       "82399         112           1  \n",
       "82400          78           2  \n",
       "82401         117           2  \n",
       "82402         149           3  \n",
       "82403         142           2  \n",
       "\n",
       "[82404 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb240f",
   "metadata": {},
   "source": [
    "# Baseline experiment\n",
    "\n",
    "Data preparation\n",
    "- Feature extraction: Extracts from sequence only (AAC format)\n",
    "- Label encoding\n",
    "\n",
    "Training\n",
    "- One VS Rest classifier (Logistic Regression)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56710249",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1affdbd9",
   "metadata": {},
   "source": [
    "### Feature Extraction: Turning sequence into numeric features\n",
    "\n",
    "To produce fixed size representations of the amino acid sequence (given our different lengths of sequences), we have the following common methods in the field of protein prediction\n",
    "- Amino Acid Composition (AAC) `--> choose this method as baseline`\n",
    "  - Count the frequency of each of the 20 standard amino acids.\n",
    "- k-mer frequencies (dipeptides or tripeptides) `--> later tested for improvement`\n",
    "  - Count how often each possible 2-mer or 3-mer appears.\n",
    "- Physicochemical properties `--> later tested for improvement`\n",
    "  - Compute features like:\n",
    "    - Hydrophobicity\n",
    "    - Charge\n",
    "    - Molecular weight\n",
    "    - Fraction of polar, aromatic, small amino acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032c33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of AAC feature matrix: (82404, 20) \n",
      "---\n",
      "[0.     0.     0.     0.0625 0.0625 0.0625 0.     0.0625 0.0625 0.0625\n",
      " 0.125  0.     0.0625 0.0625 0.1875 0.     0.     0.     0.0625 0.125 ]\n"
     ]
    }
   ],
   "source": [
    "# AAC\n",
    "from collections import Counter\n",
    "\n",
    "standard_aas = 'ACDEFGHIKLMNPQRSTVWY'  # 20 standard axit amin sequence characters\n",
    "\n",
    "def extract_sequence_features(seq):\n",
    "    \"\"\"Convert a protein sequence into a 20-dim AAC vector.\"\"\"\n",
    "    length = len(seq)\n",
    "    counts = Counter(seq)\n",
    "    return np.array([counts.get(aa, 0) / length for aa in standard_aas])\n",
    "\n",
    "# Example: Apply to dataframe\n",
    "X_aac = np.stack(df['sequence'].apply(extract_sequence_features))\n",
    "\n",
    "print(\"Shape of AAC feature matrix:\", X_aac.shape, \"\\n---\")\n",
    "print(X_aac[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23edf7",
   "metadata": {},
   "source": [
    "### Label Encoding (Failed attempt): Turning GO terms to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436373cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82404, 26125) int64\n"
     ]
    }
   ],
   "source": [
    "# # labels (GO terms)\n",
    "# import ast\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# # Convert string to list\n",
    "# df['labels'] = df['labels'].apply(ast.literal_eval)\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# Y = mlb.fit_transform(df['labels'])\n",
    "# print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6294488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82404, 26125) int64\n"
     ]
    }
   ],
   "source": [
    "# # Since the memory requirement is too much --> Create a sparse version for Y\n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# Y_sparse = csr_matrix(Y)  # stores only non-zero entries\n",
    "# print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1319c6",
   "metadata": {},
   "source": [
    "ðŸ’¡ Reason of failing:\n",
    "- The original Y (non-sparse) takes up too much memory --> unable to train\n",
    "- The sparse Y allows training --> but training takes too long\n",
    "- Bottom line: A target matrix of (82404, 26125) is too large, extremely sparse, and makes the modelâ€™s final layer enormous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d8e79",
   "metadata": {},
   "source": [
    "### Label Encoding: ontology-specific encoding\n",
    "\n",
    "For each sequence, the output dimension of 26125 may be too large --> We divide it into three subsets (one for MF, one for BP, and one for CC). As a result, for each sequence, we will have 3 vectors as follows using multi-hot encoding (i.e. simply one-hot for multi-classification problems)\n",
    "- For MF: [0 1 0 1 ... 0] of length num_unique(MF_GO_temrs)\n",
    "- For BP: [0 1 0 1 ... 0] of length num_unique(BP_GO_temrs)\n",
    "- For CC: [0 1 0 1 ... 0] of length num_unique(CC_GO_temrs)\n",
    "\n",
    "Then we will train three separate models for each ontology. We use three models to predict for a single example in the test set, and gather the predictions.\n",
    "\n",
    "However, in the implementation, make sure the label has 82,404 examples (i.e. 82,404 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf205d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique P terms: 16858\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [82404, 59958]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n    estimator.fit(X, y, **fit_params)\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1222, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1389, in check_X_y\n    check_consistent_length(X, y)\n  File \"c:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 475, in check_consistent_length\n    raise ValueError(\nValueError: Found input variables with inconsistent numbers of samples: [82404, 59958]\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m mlb_dict[aspect] = mlb\n\u001b[32m     26\u001b[39m model = OneVsRestClassifier(LogisticRegression(max_iter=\u001b[32m100\u001b[39m, solver=\u001b[33m'\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m'\u001b[39m, C=\u001b[32m0.5\u001b[39m, random_state=\u001b[32m42\u001b[39m), n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_ont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m models[aspect] = model\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maspect\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trained successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\multiclass.py:376\u001b[39m, in \u001b[36mOneVsRestClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    372\u001b[39m columns = (col.toarray().ravel() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m Y.T)\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# In cases where individual estimators are very fast to train setting\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# of spawning threads.  See joblib issue #112.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_binary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnot \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mn_features_in_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    391\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_features_in_ = \u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m].n_features_in_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1748\u001b[39m \n\u001b[32m   1749\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1752\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1755\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1757\u001b[39m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1785\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1789\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    739\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    742\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    743\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    744\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    762\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [82404, 59958]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_terms_df = pd.read_csv(\"data/Train/train_terms.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Create three label sets\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "mlb_dict = dict()\n",
    "models = dict()\n",
    "\n",
    "X_train = X_aac\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    ont_terms_df = train_terms_df[train_terms_df['aspect'] == aspect]\n",
    "    \n",
    "    protein_terms = ont_terms_df.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "    labels_list = list(protein_terms.values())\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    y_train_ont = mlb.fit_transform(labels_list)\n",
    "    \n",
    "    print(f\"Number of unique {aspect} terms: {y_train_ont.shape}\")\n",
    "    \n",
    "    mlb_dict[aspect] = mlb\n",
    "    model = OneVsRestClassifier(LogisticRegression(max_iter=100, solver='lbfgs', C=0.5, random_state=42), n_jobs=-1)\n",
    "    model.fit(X_train, y_train_ont)\n",
    "    models[aspect] = model\n",
    "    print(f\"Model for {aspect} trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab8a19",
   "metadata": {},
   "source": [
    "ðŸ’¡ 16858 + 2651 + 6616 = 26125 is actually the number of unique GO terms\n",
    "\n",
    "ðŸ’¡ Currently the shape[1] of labels are not correct --> refer to this implementation: https://www.kaggle.com/code/analyticaobscura/cafa-6-decoding-protein-mysteries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6127312",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "Configuration:\n",
    "- CPU: Intel Core i5-1135G7 (Family 6 Model 140), 1 processor, ~2.8â€¯GHz, 4 cores / 8 threads\n",
    "- RAM: 8â€¯GB (approx. 1.3â€¯GB available for programs)\n",
    "- GPU: Integrated (Intel Iris Xe Graphics)\n",
    "- OS: Windows 11 Home Single Language, 64-bit\n",
    "- Python: 3.11.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
