{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CAFA6-02-Enhanced feature extraction\n\nImprovement from CAFA6-01: 71 features --> 77 features.\n\n6 new features come from:\n- Add secondary structure predictions (Helix/Sheet/Coil fractions).\n- Include global physicochemical descriptors (pI, GRAVY, instability index).\n\nReferences:\n- https://www.kaggle.com/code/analyticaobscura/cafa-6-decoding-protein-mysteries\n\n---","metadata":{}},{"cell_type":"code","source":"!pip install biopython > /dev/null","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:05.333991Z","iopub.execute_input":"2025-12-01T05:00:05.334314Z","iopub.status.idle":"2025-12-01T05:00:13.280213Z","shell.execute_reply.started":"2025-12-01T05:00:05.334281Z","shell.execute_reply":"2025-12-01T05:00:13.279001Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from Bio import SeqIO  # parse fasta file\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:13.283055Z","iopub.execute_input":"2025-12-01T05:00:13.283417Z","iopub.status.idle":"2025-12-01T05:00:13.733976Z","shell.execute_reply.started":"2025-12-01T05:00:13.283348Z","shell.execute_reply":"2025-12-01T05:00:13.732751Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# file paths\nTRAIN_TERMS = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\"\nTRAIN_SEQ = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta\"\nTRAIN_TAXONOMY = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_taxonomy.tsv\"\nTEST_SEQ = \"/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta\"\nGO_WEIGHTS = \"/kaggle/input/cafa-6-protein-function-prediction/IA.tsv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:13.735093Z","iopub.execute_input":"2025-12-01T05:00:13.735671Z","iopub.status.idle":"2025-12-01T05:00:13.741053Z","shell.execute_reply.started":"2025-12-01T05:00:13.735645Z","shell.execute_reply":"2025-12-01T05:00:13.739253Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Step 1: Turn into a unified dataFrame\n\n---","metadata":{}},{"cell_type":"code","source":"train_terms_df = pd.read_csv(TRAIN_TERMS, sep=\"\\t\")  # identifier --> label\ntrain_taxonomy_df = pd.read_csv(TRAIN_TAXONOMY, sep=\"\\t\", names=['EntryID', 'taxonomyID'])  # identifier --> taxonomy\nia_df = pd.read_csv(GO_WEIGHTS, sep='\\t', names=['term', 'ia'])  # GO --> weight\n\ndef load_fasta_to_dataframe(file_path, is_train=True):\n    records = []\n    parser = SeqIO.parse(file_path, \"fasta\")\n    for record in parser:\n        entry_id = record.id.split('|')[1] if is_train and '|' in record.id else record.id.split()[0]\n        records.append({'EntryID': entry_id, 'sequence': str(record.seq)})\n    return pd.DataFrame(records)\n\ntrain_sequences_df = load_fasta_to_dataframe(TRAIN_SEQ, is_train=True)  # identifier --> input: amino acid sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:13.743253Z","iopub.execute_input":"2025-12-01T05:00:13.744420Z","iopub.status.idle":"2025-12-01T05:00:15.262590Z","shell.execute_reply.started":"2025-12-01T05:00:13.744351Z","shell.execute_reply":"2025-12-01T05:00:15.261641Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(train_terms_df[0:2], \"\\n---\")\nprint(train_taxonomy_df[0:2], \"\\n---\")\nprint(ia_df[0:2], \"\\n---\")\nprint(train_sequences_df[0:2], \"\\n---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:15.263587Z","iopub.execute_input":"2025-12-01T05:00:15.263844Z","iopub.status.idle":"2025-12-01T05:00:15.285573Z","shell.execute_reply.started":"2025-12-01T05:00:15.263824Z","shell.execute_reply":"2025-12-01T05:00:15.284666Z"}},"outputs":[{"name":"stdout","text":"  EntryID        term aspect\n0  Q5W0B1  GO:0000785      C\n1  Q5W0B1  GO:0004842      F \n---\n      EntryID  taxonomyID\n0  A0A0C5B5G6        9606\n1      A0JNW5        9606 \n---\n         term        ia\n0  GO:0000001  0.000000\n1  GO:0000002  2.849666 \n---\n      EntryID                                           sequence\n0  A0A0C5B5G6                                   MRWQEMGYIFYPRKLR\n1      A0JNW5  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL... \n---\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Group the info above into a single data frame\nprotein_labels = train_terms_df.groupby('EntryID')['term'].apply(list).reset_index(name='labels')  # turn all EntryID duplicates into one EntryID with their terms forming a list\ntrain_df_eda = pd.merge(train_sequences_df, train_taxonomy_df, on='EntryID', how='left')\ntrain_df_eda = pd.merge(train_df_eda, protein_labels, on='EntryID', how='inner')\ntrain_df_eda['seq_length'] = train_df_eda['sequence'].str.len()\ntrain_df_eda['num_labels'] = train_df_eda['labels'].str.len()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:15.286594Z","iopub.execute_input":"2025-12-01T05:00:15.286927Z","iopub.status.idle":"2025-12-01T05:00:17.288716Z","shell.execute_reply.started":"2025-12-01T05:00:15.286900Z","shell.execute_reply":"2025-12-01T05:00:17.287956Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(protein_labels[82399:82401])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:17.291092Z","iopub.execute_input":"2025-12-01T05:00:17.291358Z","iopub.status.idle":"2025-12-01T05:00:17.298587Z","shell.execute_reply.started":"2025-12-01T05:00:17.291334Z","shell.execute_reply":"2025-12-01T05:00:17.297528Z"}},"outputs":[{"name":"stdout","text":"      EntryID                    labels\n82399  X2JI34  [GO:0106223, GO:0051762]\n82400  X4Y2L4  [GO:0033906, GO:0030214]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Unified data frame\ntrain_df_eda","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:17.299396Z","iopub.execute_input":"2025-12-01T05:00:17.299821Z","iopub.status.idle":"2025-12-01T05:00:17.337284Z","shell.execute_reply.started":"2025-12-01T05:00:17.299796Z","shell.execute_reply":"2025-12-01T05:00:17.336131Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"          EntryID                                           sequence  \\\n0      A0A0C5B5G6                                   MRWQEMGYIFYPRKLR   \n1          A0JNW5  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...   \n2          A0JP26  MVAEVCSMPAASAVKKPFDLRSKMGKWCHHRFPCCRGSGKSNMGTS...   \n3          A0PK11  MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...   \n4          A1A4S6  MGLQPLEFSDCYLDSPWFRERIRAHEAELERTNKFIKELIKDGKNL...   \n...           ...                                                ...   \n82399      Q9UTM1  MSKLKAQSALQKLIESQKNPNANEDGYFRRKRLAKKERPFEPKKLV...   \n82400      Q9Y7I1  MSSNSNTDHSTGDNRSKSEKQTDLRNALRETESHGMPPLRGPAGFP...   \n82401      Q9Y7P7  MRSNNSSLVHCCWVSPPSLTRLPAFPSPRILSPCYCYNKRIRPFRG...   \n82402      Q9Y7Q3  MHSSRRKYNDMWTARLLIRSDQKEEKYPSFKKNAGKAINAHLIPKL...   \n82403      Q9Y816  MITEFIKSFLLFFFLPFFLSMPMIFATLGEFTDDQTHHYSTLPSCD...   \n\n       taxonomyID                                             labels  \\\n0            9606  [GO:0001649, GO:0033687, GO:0005615, GO:000563...   \n1            9606  [GO:0120013, GO:0034498, GO:0005769, GO:012000...   \n2            9606                                       [GO:0005515]   \n3            9606                           [GO:0007605, GO:0005515]   \n4            9606  [GO:0005829, GO:0010008, GO:0005515, GO:000509...   \n...           ...                                                ...   \n82399      284812                                       [GO:0005730]   \n82400      284812                           [GO:0005634, GO:0005829]   \n82401      284812                           [GO:0005634, GO:0005829]   \n82402      284812               [GO:0005634, GO:0005739, GO:0005829]   \n82403      284812                           [GO:0005737, GO:0005783]   \n\n       seq_length  num_labels  \n0              16          14  \n1            1464           8  \n2             581           1  \n3             232           2  \n4             786           5  \n...           ...         ...  \n82399         112           1  \n82400          78           2  \n82401         117           2  \n82402         149           3  \n82403         142           2  \n\n[82404 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>sequence</th>\n      <th>taxonomyID</th>\n      <th>labels</th>\n      <th>seq_length</th>\n      <th>num_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A0C5B5G6</td>\n      <td>MRWQEMGYIFYPRKLR</td>\n      <td>9606</td>\n      <td>[GO:0001649, GO:0033687, GO:0005615, GO:000563...</td>\n      <td>16</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0JNW5</td>\n      <td>MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...</td>\n      <td>9606</td>\n      <td>[GO:0120013, GO:0034498, GO:0005769, GO:012000...</td>\n      <td>1464</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0JP26</td>\n      <td>MVAEVCSMPAASAVKKPFDLRSKMGKWCHHRFPCCRGSGKSNMGTS...</td>\n      <td>9606</td>\n      <td>[GO:0005515]</td>\n      <td>581</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0PK11</td>\n      <td>MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...</td>\n      <td>9606</td>\n      <td>[GO:0007605, GO:0005515]</td>\n      <td>232</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A1A4S6</td>\n      <td>MGLQPLEFSDCYLDSPWFRERIRAHEAELERTNKFIKELIKDGKNL...</td>\n      <td>9606</td>\n      <td>[GO:0005829, GO:0010008, GO:0005515, GO:000509...</td>\n      <td>786</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>82399</th>\n      <td>Q9UTM1</td>\n      <td>MSKLKAQSALQKLIESQKNPNANEDGYFRRKRLAKKERPFEPKKLV...</td>\n      <td>284812</td>\n      <td>[GO:0005730]</td>\n      <td>112</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>82400</th>\n      <td>Q9Y7I1</td>\n      <td>MSSNSNTDHSTGDNRSKSEKQTDLRNALRETESHGMPPLRGPAGFP...</td>\n      <td>284812</td>\n      <td>[GO:0005634, GO:0005829]</td>\n      <td>78</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>82401</th>\n      <td>Q9Y7P7</td>\n      <td>MRSNNSSLVHCCWVSPPSLTRLPAFPSPRILSPCYCYNKRIRPFRG...</td>\n      <td>284812</td>\n      <td>[GO:0005634, GO:0005829]</td>\n      <td>117</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>82402</th>\n      <td>Q9Y7Q3</td>\n      <td>MHSSRRKYNDMWTARLLIRSDQKEEKYPSFKKNAGKAINAHLIPKL...</td>\n      <td>284812</td>\n      <td>[GO:0005634, GO:0005739, GO:0005829]</td>\n      <td>149</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>82403</th>\n      <td>Q9Y816</td>\n      <td>MITEFIKSFLLFFFLPFFLSMPMIFATLGEFTDDQTHHYSTLPSCD...</td>\n      <td>284812</td>\n      <td>[GO:0005737, GO:0005783]</td>\n      <td>142</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>82404 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Step 2: Exploratory Data Analysis (EDA)\n\nAlready implemented in a local notebook\n\n---","metadata":{}},{"cell_type":"markdown","source":"EDA - Summary\n- `82,404` training examples (each example is a sequence of amino acids of different lengths)\n- The `20/1381` most frequent taxonomyIDs (i.e. species) take up `91%` of the dataset \n- The `700/2906` most probable sequence lengths are within `[10,926]` which take up `81%` of the dataset. The most frequent sequence length is `359` characters.\n- There is a weak positive correlation between `seq_length` and `num_labels`, meaning longer sequences sometimes yield more GOs\n- Some `taxonomyIDs` have more `num_labels` than others (i.e. the mean `num_labels` is `2.791703`, while 25% of the  data has more than 3.375 and up to 16 `num_labels`)\n- The annotation:\n  - `537,027` annotated GO terms\n  - `26,125` unique GO terms\n  - Out of the three sub-ontologies, `Biological Process (P)` is the most annotated, then `Cellular Component (C)`, finally `Molecular Function (F)`\n- (ðŸ’¡) A standard protein sequence is made up of 20 amino acid letters, each represented by a single uppercase English letter. \n  - A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y\n  - Besides the 20 standard amino acids, protein sequences sometimes include:\n    - `B` --> Aspartic acid (D) or Asparagine (N)\n    - `Z` --> Glutamic acid (E) or Glutamine (Q)\n    - `X` --> Unknown amino acid\n    - `J` --> Leucine (L) or Isoleucine (I)\n    - `U` --> Selenocysteine\n    - `O` --> Pyrrolysine","metadata":{}},{"cell_type":"markdown","source":"## Step 3: Feature extraction\n\nFor the baseline performance, we only use the column `sequence` in our unified dataFrame to extract the features.\n\nHere are some methods to turn the sequence into meaningful numerical values\n- Amino Acid Composition (AAC)\n  - Computes the relative frequency of each of the 20 standard amino acids.  \n  - Captures the overall chemical makeup of the protein.\n- Physicochemical Properties\n  - Global properties correlated with structure and function, including:  \n    - Hydrophobic fraction  \n    - Charged amino acid fraction  \n    - Molecular weight (log-scaled)  \n    - Sequence length (log-scaled)\n- CTD-style Group Composition \n  - Groups amino acids by shared chemical characteristics and measures their proportions, such as:  \n    - Hydrophobic  \n    - Polar  \n    - Positive charge  \n    - Negative charge  \n    - Aromatic  \n    - Aliphatic  \n    - Small residues\n- k-mer Frequencies (dipeptides and tripeptides)\n  - Counts the frequency of selected short patterns (2-mers and 3-mers).  \n  - Captures local sequence motifs that composition alone cannot represent.\n- Secondary Structure Fractions\n  - Estimates the proportion of each type of secondary structure in the protein:  \n    - Alpha-helix  \n    - Beta-sheet  \n    - Coil  \n  - Provides structural context that affects protein function.\n- Global Physicochemical Descriptors\n  - Includes sequence-level chemical properties:  \n    - Isoelectric point (pI)  \n    - Hydropathy index (GRAVY)  \n    - Instability index  \n  - Helps capture overall biochemical characteristics affecting stability and interactions.\n  \n---","metadata":{}},{"cell_type":"code","source":"AA_ORDER = 'ACDEFGHIKLMNPQRSTVWY'\n\nAA_WEIGHTS = {\n    'A': 89, 'C': 121, 'D': 133, 'E': 147, 'F': 165, 'G': 75, 'H': 155,\n    'I': 131, 'K': 146, 'L': 131, 'M': 149, 'N': 132, 'P': 115, 'Q': 146,\n    'R': 174, 'S': 105, 'T': 119, 'V': 117, 'W': 204, 'Y': 181\n}\n\nCTD_GROUPS = {\n    'hydrophobic': set('AILMFWYV'),\n    'polar': set('STNQ'),\n    'positive': set('RK'),\n    'negative': set('DE'),\n    'aromatic': set('FWY'),\n    'aliphatic': set('ILV'),\n    'small': set('ACDGNPSTV'),\n}\n\nTOP_DIPEPTIDES = [\n    'AL','LA','LE','EA','AA','AS','SA','EL','LL','AE',\n    'SE','ES','GA','AG','VA','AV','LV','VL','LS','SL'\n]\n\nTOP_TRIPEPTIDES = [\n    'ALA','LEA','EAL','LAL','AAA','LLE','ELE','ALE','GAL','ASA',\n    'VLA','LAV','SLS','LSL','GLA','LAG','AVL','VLA','SLE','LES'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:17.338547Z","iopub.execute_input":"2025-12-01T05:00:17.338887Z","iopub.status.idle":"2025-12-01T05:00:17.347384Z","shell.execute_reply.started":"2025-12-01T05:00:17.338848Z","shell.execute_reply":"2025-12-01T05:00:17.346211Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from collections import Counter\nfrom Bio.SeqUtils.ProtParam import ProteinAnalysis\nimport numpy as np\n\ndef extract_sequence_features(seq):\n    \"\"\"Extracts 77 numerical features from a protein sequence, safely ignoring unknown amino acids.\"\"\"\n    if not seq:\n        return np.zeros(77)\n\n    length = len(seq)\n    aa_counts = Counter(seq)\n\n    # --- 1. AAC (20 features)\n    AA_ORDER = 'ACDEFGHIKLMNPQRSTVWY'\n    aa_freq = np.array([aa_counts.get(aa, 0) / length for aa in AA_ORDER])\n\n    # --- 2. Physicochemical (4 features)\n    AA_WEIGHTS = {'A': 89, 'C': 121, 'D': 133, 'E': 147, 'F': 165, 'G': 75,\n                  'H': 155, 'I': 131, 'K': 146, 'L': 131, 'M': 149, 'N': 132,\n                  'P': 115, 'Q': 146, 'R': 174, 'S': 105, 'T': 119, 'V': 117,\n                  'W': 204, 'Y': 181}\n    hydrophobic = sum(aa_counts.get(a, 0) for a in 'AILMFWYV') / length\n    charged = sum(aa_counts.get(a, 0) for a in 'DEKR') / length\n    mol_weight = sum(aa_counts.get(aa, 0) * AA_WEIGHTS.get(aa, 0) for aa in aa_counts if aa in AA_WEIGHTS)\n    physchem = np.array([np.log1p(length), hydrophobic, charged, np.log1p(mol_weight)])\n\n    # --- 3. CTD group composition (7 features)\n    CTD_GROUPS = {\n        'hydrophobic': set('AILMFWYV'),\n        'polar': set('STNQ'),\n        'positive': set('RK'),\n        'negative': set('DE'),\n        'aromatic': set('FWY'),\n        'aliphatic': set('ILV'),\n        'small': set('ACDGNPSTV')\n    }\n    ctd = np.array([sum(1 for aa in seq if aa in group) / length for group in CTD_GROUPS.values()])\n\n    # --- 4. Dipeptides (20 features)\n    TOP_DIPEPTIDES = ['AL', 'LA', 'LE', 'EA', 'AA', 'AS', 'SA', 'EL', 'LL', 'AE',\n                      'SE', 'ES', 'GA', 'AG', 'VA', 'AV', 'LV', 'VL', 'LS', 'SL']\n    if length > 1:\n        dip_counts = Counter(seq[i:i+2] for i in range(length - 1))\n        dipep = np.array([dip_counts.get(dp, 0) / (length - 1) for dp in TOP_DIPEPTIDES])\n    else:\n        dipep = np.zeros(len(TOP_DIPEPTIDES))\n\n    # --- 5. Tripeptides (20 features)\n    TOP_TRIPEPTIDES = ['ALA', 'LEA', 'EAL', 'LAL', 'AAA', 'LLE', 'ELE', 'ALE', 'GAL', 'ASA',\n                       'VLA', 'LAV', 'SLS', 'LSL', 'GLA', 'LAG', 'AVL', 'VLA', 'SLE', 'LES']\n    if length > 2:\n        tri_counts = Counter(seq[i:i+3] for i in range(length - 2))\n        tripep = np.array([tri_counts.get(tp, 0) / (length - 2) for tp in TOP_TRIPEPTIDES])\n    else:\n        tripep = np.zeros(len(TOP_TRIPEPTIDES))\n\n    # --- 6. Secondary structure + global descriptors (6 features)\n    safe_seq = ''.join([aa for aa in seq if aa in AA_ORDER])\n    if safe_seq:\n        analysed_seq = ProteinAnalysis(safe_seq)\n        # Secondary structure fractions\n        helix, sheet, coil = analysed_seq.secondary_structure_fraction()\n        ss_fraction = np.array([helix, sheet, coil])\n        # Global descriptors: pI, GRAVY, instability index\n        global_physchem = np.array([\n            analysed_seq.isoelectric_point(),\n            analysed_seq.gravy(),\n            analysed_seq.instability_index(),\n        ])\n    else:\n        ss_fraction = np.zeros(3)\n        global_physchem = np.zeros(3)\n\n    # concatenate all 77 features\n    return np.concatenate([aa_freq, physchem, ctd, dipep, tripep, ss_fraction, global_physchem])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:17.348953Z","iopub.execute_input":"2025-12-01T05:00:17.349267Z","iopub.status.idle":"2025-12-01T05:00:17.373740Z","shell.execute_reply.started":"2025-12-01T05:00:17.349234Z","shell.execute_reply":"2025-12-01T05:00:17.372951Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Extract features for training. This will be the same as the AAC matrix above.\n# However, in this code, we also create y_train_proteins which contains the EntryID of all 82404 examples. This will be used later for label encoding.\n\nfrom tqdm import tqdm\n\nfeatures, protein_identifiers = list(), list()\n\nentry_ids = set(train_terms_df['EntryID'].unique())\ntrain_sequences_dict = train_sequences_df.set_index('EntryID')['sequence'].to_dict()  # simply turn train_sequences_df into a dict\n\nfor entry_id, sequence in tqdm(train_sequences_dict.items(), desc=\"Processing Train Sequences\"):\n    if entry_id in entry_ids:\n        features.append(extract_sequence_features(sequence))\n        protein_identifiers.append(entry_id)\n        \nX_train = np.array(features)\nprint(f\"Training feature matrix shape: {X_train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:00:17.374569Z","iopub.execute_input":"2025-12-01T05:00:17.374803Z","iopub.status.idle":"2025-12-01T05:01:25.980009Z","shell.execute_reply.started":"2025-12-01T05:00:17.374784Z","shell.execute_reply":"2025-12-01T05:01:25.978925Z"}},"outputs":[{"name":"stderr","text":"Processing Train Sequences: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82404/82404 [01:08<00:00, 1205.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training feature matrix shape: (82404, 77)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(len(protein_identifiers))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:01:25.980969Z","iopub.execute_input":"2025-12-01T05:01:25.981246Z","iopub.status.idle":"2025-12-01T05:01:25.986981Z","shell.execute_reply.started":"2025-12-01T05:01:25.981222Z","shell.execute_reply":"2025-12-01T05:01:25.985691Z"}},"outputs":[{"name":"stdout","text":"82404\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"ðŸ’¡ As illustrated above, the features `X_train` are of shape (82404, 77) and the `protein_identifies` stores 82404 entryIDs accordingly.","metadata":{}},{"cell_type":"markdown","source":"## Step 4: Label encoding and Training\n\nI have tried two methods of encoding the labels, but only the latter works.\n\n- Method 1: Turning 26125 unique GO terms into multi-hot vectors\n    - This results in `y_train` of shape `(82404, 26125)`, which is too large, extremely sparse, and makes the modelâ€™s final layer enormous.\n    - This method fails\n- Method 2: We divide the label in method 1 into three subsets (one for MF, one for BP, and one for CC).\n    -  As a result, for each sequence, we will have 3 vectors as follows using multi-hot encoding (i.e. simply one-hot for multi-classification problems)\n        - For MF: [0 1 0 1 ... 0] of length num_unique(MF_GO_temrs)\n        - For BP: [0 1 0 1 ... 0] of length num_unique(BP_GO_temrs)\n        - For CC: [0 1 0 1 ... 0] of length num_unique(CC_GO_temrs)\n    - Then we will train three separate models for each ontology. We use three models to predict for a single example in the test set, and gather the predictions.\n\n---","metadata":{}},{"cell_type":"code","source":"# Create three label sets\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\nmlb_dict = dict()\nmodels = dict()\n\nfor aspect in tqdm(['P', 'C', 'F'], desc=\"Training models\"):\n    # Filter the train_terms_df based on aspect\n    ont_terms_df = train_terms_df[train_terms_df['aspect'] == aspect]\n\n    # Group the dataFrame based on the EntryID, turn all the GO terms to a list, finally turns this dataFrame to a dict {entryID: terms}\n    protein_terms = ont_terms_df.groupby('EntryID')['term'].apply(list).to_dict()\n\n    # Create a list of labels for this aspect, if an entryID doesn't exist in this aspect, give it a []\n    # This ensures y_train is of shape (82404, ...)\n    labels = [protein_terms.get(entry_id, []) for entry_id in protein_identifiers]\n\n    # Multi-hot encoding, use sparse representation\n    mlb = MultiLabelBinarizer(sparse_output=True)\n    y_train = mlb.fit_transform(labels)\n    \n    print(f\"y_train shape for {aspect} ontology: {y_train.shape} \\t\\t Number of unique {aspect} terms: {y_train.shape[1]}\")\n\n    # Save to dict\n    mlb_dict[aspect] = mlb\n    model = OneVsRestClassifier(LogisticRegression(max_iter=600, solver='lbfgs', C=0.5, random_state=42), n_jobs=-1)\n    model.fit(X_train, y_train)\n    models[aspect] = model\n    print(f\"Model for {aspect} trained successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:01:25.988005Z","iopub.execute_input":"2025-12-01T05:01:25.988356Z","iopub.status.idle":"2025-12-01T08:52:49.698508Z","shell.execute_reply.started":"2025-12-01T05:01:25.988328Z","shell.execute_reply":"2025-12-01T08:52:49.697629Z"}},"outputs":[{"name":"stderr","text":"Training models:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"y_train shape for P ontology: (82404, 16858) \t\t Number of unique P terms: 16858\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\nTraining models:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [2:29:37<4:59:15, 8977.86s/it]","output_type":"stream"},{"name":"stdout","text":"Model for P trained successfully.\ny_train shape for C ontology: (82404, 2651) \t\t Number of unique C terms: 2651\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\nTraining models:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [2:56:36<1:17:29, 4649.18s/it]","output_type":"stream"},{"name":"stdout","text":"Model for C trained successfully.\ny_train shape for F ontology: (82404, 6616) \t\t Number of unique F terms: 6616\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\nTraining models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [3:51:22<00:00, 4627.60s/it]  ","output_type":"stream"},{"name":"stdout","text":"Model for F trained successfully.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Step 5: Inference and Submission","metadata":{}},{"cell_type":"code","source":"test_sequences_df = load_fasta_to_dataframe(TEST_SEQ, is_train=False)\ntest_entry_ids = test_sequences_df['EntryID'].tolist()\ntest_sequences_dict = test_sequences_df.set_index('EntryID')['sequence'].to_dict()\n\nBATCH_SIZE = 5000  # avoid overload\nsubmission_list = []\n\nfor i in tqdm(range(0, len(test_entry_ids), BATCH_SIZE), desc=\"Predicting on Test Set\"):\n    batch_entry_ids = test_entry_ids[i:i + BATCH_SIZE]\n    batch_seqs = [test_sequences_dict[entry_id] for entry_id in batch_entry_ids]\n    X_batch = np.array([extract_sequence_features(seq) for seq in batch_seqs])\n    \n    for aspect, model in models.items():\n        mlb = mlb_dict[aspect]\n        y_pred_proba = model.predict_proba(X_batch)\n        \n        for j, entry_id in enumerate(batch_entry_ids):\n            probs = y_pred_proba[j]\n            candidate_indices = np.where(probs > 0.02)[0]\n            \n            for idx in candidate_indices:\n                submission_list.append((entry_id, mlb.classes_[idx], round(probs[idx], 3)))\n\nprint(f\"Generated {len(submission_list):,} total predictions.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:52:49.699543Z","iopub.execute_input":"2025-12-01T08:52:49.700030Z","iopub.status.idle":"2025-12-01T09:09:12.118438Z","shell.execute_reply.started":"2025-12-01T08:52:49.700006Z","shell.execute_reply":"2025-12-01T09:09:12.117427Z"}},"outputs":[{"name":"stderr","text":"Predicting on Test Set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [16:19<00:00, 21.77s/it]","output_type":"stream"},{"name":"stdout","text":"Generated 4,886,535 total predictions.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"submission_df = pd.DataFrame(submission_list, columns=['Protein Id', 'GO Term Id', 'Prediction'])\n\nprint(\"Applying 1500 prediction limit per protein...\")\nsubmission_df = submission_df.sort_values(by=['Protein Id', 'Prediction'], ascending=[True, False])\nfinal_submission_df = submission_df.groupby('Protein Id').head(1500).reset_index(drop=True)\nfinal_submission_df.to_csv('submission.tsv', sep='\\t', index=False, header=False)\n\nprint(\"\\nSubmission file 'submission.tsv' created successfully.\")\nprint(f\"Total predictions in final submission: {len(final_submission_df):,}\")\nprint(\"Submission DataFrame Head:\")\ndisplay(final_submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T09:09:12.119391Z","iopub.execute_input":"2025-12-01T09:09:12.119914Z","iopub.status.idle":"2025-12-01T09:09:25.162191Z","shell.execute_reply.started":"2025-12-01T09:09:12.119892Z","shell.execute_reply":"2025-12-01T09:09:25.161260Z"}},"outputs":[{"name":"stdout","text":"Applying 1500 prediction limit per protein...\n\nSubmission file 'submission.tsv' created successfully.\nTotal predictions in final submission: 4,768,132\nSubmission DataFrame Head:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Protein Id  GO Term Id  Prediction\n0  A0A017SE81  GO:0005515       0.230\n1  A0A017SE81  GO:0005886       0.197\n2  A0A017SE81  GO:0005739       0.132\n3  A0A017SE81  GO:0005829       0.086\n4  A0A017SE81  GO:0005634       0.066","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Protein Id</th>\n      <th>GO Term Id</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A017SE81</td>\n      <td>GO:0005515</td>\n      <td>0.230</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A017SE81</td>\n      <td>GO:0005886</td>\n      <td>0.197</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A017SE81</td>\n      <td>GO:0005739</td>\n      <td>0.132</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A017SE81</td>\n      <td>GO:0005829</td>\n      <td>0.086</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A017SE81</td>\n      <td>GO:0005634</td>\n      <td>0.066</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15}]}