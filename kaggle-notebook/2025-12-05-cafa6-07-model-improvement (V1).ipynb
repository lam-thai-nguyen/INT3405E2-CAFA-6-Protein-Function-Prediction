{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAFA6-07-Model Improvement\n",
    "\n",
    "Improvement from CAFA6-03: OneVsRest(LogisticRegression) --> Customized MLP\n",
    "\n",
    "Future direction: Use model ensemble\n",
    "\n",
    "References:\n",
    "- https://www.kaggle.com/code/analyticaobscura/cafa-6-decoding-protein-mysteries\n",
    "- (ESM-2 embeddings 320 features) https://www.kaggle.com/code/dalloliogm/compute-protein-embeddings-with-esm2-esm-c/notebook\n",
    "- (MLP with ESM2) https://www.kaggle.com/code/jwang2025learning/cafa-6-function-prediction-using-prott5?scriptVersionId=282801093\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:26:32.072677Z",
     "iopub.status.busy": "2025-12-05T07:26:32.072413Z",
     "iopub.status.idle": "2025-12-05T07:26:37.527277Z",
     "shell.execute_reply": "2025-12-05T07:26:37.526302Z",
     "shell.execute_reply.started": "2025-12-05T07:26:32.072655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install biopython > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load CAFA6 files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:26:37.531107Z",
     "iopub.status.busy": "2025-12-05T07:26:37.530864Z",
     "iopub.status.idle": "2025-12-05T07:26:37.852893Z",
     "shell.execute_reply": "2025-12-05T07:26:37.852166Z",
     "shell.execute_reply.started": "2025-12-05T07:26:37.531074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO  # parse fasta file\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:26:37.854200Z",
     "iopub.status.busy": "2025-12-05T07:26:37.853727Z",
     "iopub.status.idle": "2025-12-05T07:26:37.858216Z",
     "shell.execute_reply": "2025-12-05T07:26:37.857432Z",
     "shell.execute_reply.started": "2025-12-05T07:26:37.854173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CAFA6 file paths\n",
    "TRAIN_TERMS = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\"\n",
    "TRAIN_SEQ = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta\"\n",
    "TRAIN_TAXONOMY = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_taxonomy.tsv\"\n",
    "TEST_SEQ = \"/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:26:43.134525Z",
     "iopub.status.busy": "2025-12-05T07:26:43.134277Z",
     "iopub.status.idle": "2025-12-05T07:26:46.852363Z",
     "shell.execute_reply": "2025-12-05T07:26:46.851722Z",
     "shell.execute_reply.started": "2025-12-05T07:26:43.134504Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 82404 train and 224309 test sequences\n"
     ]
    }
   ],
   "source": [
    "# Dict {entryId, seq}\n",
    "train_sequences = {rec.id: str(rec.seq) for rec in SeqIO.parse(TRAIN_SEQ, 'fasta')}\n",
    "test_sequences  = {rec.id: str(rec.seq) for rec in SeqIO.parse(TEST_SEQ,  'fasta')}\n",
    "\n",
    "print(f'Loaded {len(train_sequences)} train and {len(test_sequences)} test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:26:46.853878Z",
     "iopub.status.busy": "2025-12-05T07:26:46.853390Z",
     "iopub.status.idle": "2025-12-05T07:26:46.974258Z",
     "shell.execute_reply": "2025-12-05T07:26:46.973631Z",
     "shell.execute_reply.started": "2025-12-05T07:26:46.853849Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dict: ('sp|A0A0C5B5G6|MOTSC_HUMAN', 'MRWQEMGYIFYPRKLR')\n",
      "Test dict: ('A0A0C5B5G6', 'MRWQEMGYIFYPRKLR')\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dict:\", list(train_sequences.items())[0])\n",
    "print(\"Test dict:\", list(test_sequences.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:26:48.720489Z",
     "iopub.status.busy": "2025-12-05T07:26:48.719778Z",
     "iopub.status.idle": "2025-12-05T07:26:48.740590Z",
     "shell.execute_reply": "2025-12-05T07:26:48.739865Z",
     "shell.execute_reply.started": "2025-12-05T07:26:48.720466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ids = [i.split('|')[1] for i in train_sequences.keys()]\n",
    "test_ids = list(test_sequences.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature extraction\n",
    "\n",
    "We use the 20 features from the baseline\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:26:50.685072Z",
     "iopub.status.busy": "2025-12-05T07:26:50.684775Z",
     "iopub.status.idle": "2025-12-05T07:26:50.689614Z",
     "shell.execute_reply": "2025-12-05T07:26:50.689026Z",
     "shell.execute_reply.started": "2025-12-05T07:26:50.685052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "standard_aas = 'ACDEFGHIKLMNPQRSTVWY'  # 20 standard axit amin sequence characters\n",
    "\n",
    "def extract_sequence_features(seq):\n",
    "    \"\"\"Convert a protein sequence into a 20-dim AAC vector.\"\"\"\n",
    "    length = len(seq)\n",
    "    counts = Counter(seq)\n",
    "    return np.array([counts.get(aa, 0) / length for aa in standard_aas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:26:50.951034Z",
     "iopub.status.busy": "2025-12-05T07:26:50.950649Z",
     "iopub.status.idle": "2025-12-05T07:26:52.808646Z",
     "shell.execute_reply": "2025-12-05T07:26:52.807888Z",
     "shell.execute_reply.started": "2025-12-05T07:26:50.951016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (82404, 20)\n",
      "X_test shape: (224309, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([extract_sequence_features(i) for i in train_ids])\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "X_test = np.array([extract_sequence_features(i) for i in test_ids])\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:26:53.926357Z",
     "iopub.status.busy": "2025-12-05T07:26:53.926120Z",
     "iopub.status.idle": "2025-12-05T07:26:54.425302Z",
     "shell.execute_reply": "2025-12-05T07:26:54.424578Z",
     "shell.execute_reply.started": "2025-12-05T07:26:53.926338Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_norm shape: (82404, 20)\n",
      "X_test_norm shape: (224309, 20)\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "print(\"X_train_norm shape:\", X_train_norm.shape)\n",
    "print(\"X_test_norm shape:\", X_test_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Customized MLP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:27:07.702651Z",
     "iopub.status.busy": "2025-12-05T07:27:07.702022Z",
     "iopub.status.idle": "2025-12-05T07:27:07.785119Z",
     "shell.execute_reply": "2025-12-05T07:27:07.784380Z",
     "shell.execute_reply.started": "2025-12-05T07:27:07.702630Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:27:09.800362Z",
     "iopub.status.busy": "2025-12-05T07:27:09.799694Z",
     "iopub.status.idle": "2025-12-05T07:27:09.804979Z",
     "shell.execute_reply": "2025-12-05T07:27:09.804341Z",
     "shell.execute_reply.started": "2025-12-05T07:27:09.800341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(32, output_dim)   # no sigmoid here\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Label encoding\n",
    "\n",
    "We divide all labels into three subsets (one for MF, one for BP, and one for CC).\n",
    "-  As a result, for each sequence, we will have 3 vectors as follows using multi-hot encoding (i.e. simply one-hot for multi-classification problems)\n",
    "    - For MF: [0 1 0 1 ... 0] of length num_unique(MF_GO_temrs)\n",
    "    - For BP: [0 1 0 1 ... 0] of length num_unique(BP_GO_temrs)\n",
    "    - For CC: [0 1 0 1 ... 0] of length num_unique(CC_GO_temrs)\n",
    "- Then we will train three separate models for each ontology. We use three models to predict for a single example in the test set, and gather the predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:27:12.902284Z",
     "iopub.status.busy": "2025-12-05T07:27:12.902014Z",
     "iopub.status.idle": "2025-12-05T07:27:16.527143Z",
     "shell.execute_reply": "2025-12-05T07:27:16.526255Z",
     "shell.execute_reply.started": "2025-12-05T07:27:12.902264Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape for P ontology: (82404, 16858) \t\t Number of unique P terms: 16858\n",
      "y_train shape for C ontology: (82404, 2651) \t\t Number of unique C terms: 2651\n",
      "y_train shape for F ontology: (82404, 6616) \t\t Number of unique F terms: 6616\n"
     ]
    }
   ],
   "source": [
    "# Create three label sets\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "y_trains = dict()\n",
    "mlb_dict = dict()\n",
    "models = dict()\n",
    "\n",
    "train_terms_df = pd.read_csv(TRAIN_TERMS, sep=\"\\t\")\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    # Filter the train_terms_df based on aspect\n",
    "    ont_terms_df = train_terms_df[train_terms_df['aspect'] == aspect]\n",
    "\n",
    "    # Group the dataFrame based on the EntryID, turn all the GO terms to a list, finally turns this dataFrame to a dict {entryID: terms}\n",
    "    protein_terms = ont_terms_df.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "    # Create a list of labels for this aspect, if an entryID doesn't exist in this aspect, give it a []\n",
    "    # This ensures y_train is of shape (82404, ...)\n",
    "    labels = [protein_terms.get(entry_id, []) for entry_id in train_ids]\n",
    "\n",
    "    # Multi-hot encoding, use sparse representation\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    y_train = mlb.fit_transform(labels)\n",
    "    y_trains[aspect] = y_train\n",
    "    \n",
    "    print(f\"y_train shape for {aspect} ontology: {y_train.shape} \\t\\t Number of unique {aspect} terms: {y_train.shape[1]}\")\n",
    "\n",
    "    # Save to dict\n",
    "    mlb_dict[aspect] = mlb\n",
    "    model = MLPClassifier(input_dim=X_train.shape[1], output_dim=y_train.shape[1])\n",
    "    models[aspect] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:27:17.200823Z",
     "iopub.status.busy": "2025-12-05T07:27:17.200116Z",
     "iopub.status.idle": "2025-12-05T07:27:17.206587Z",
     "shell.execute_reply": "2025-12-05T07:27:17.205867Z",
     "shell.execute_reply.started": "2025-12-05T07:27:17.200796Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': MLPClassifier(\n",
       "   (net): Sequential(\n",
       "     (0): Linear(in_features=20, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Dropout(p=0.2, inplace=False)\n",
       "     (7): Linear(in_features=32, out_features=16858, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'C': MLPClassifier(\n",
       "   (net): Sequential(\n",
       "     (0): Linear(in_features=20, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Dropout(p=0.2, inplace=False)\n",
       "     (7): Linear(in_features=32, out_features=2651, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'F': MLPClassifier(\n",
       "   (net): Sequential(\n",
       "     (0): Linear(in_features=20, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Dropout(p=0.2, inplace=False)\n",
       "     (7): Linear(in_features=32, out_features=6616, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:27:19.172887Z",
     "iopub.status.busy": "2025-12-05T07:27:19.172327Z",
     "iopub.status.idle": "2025-12-05T07:27:19.177455Z",
     "shell.execute_reply": "2025-12-05T07:27:19.176812Z",
     "shell.execute_reply.started": "2025-12-05T07:27:19.172859Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       " \twith 250805 stored elements and shape (82404, 16858)>,\n",
       " 'C': <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       " \twith 157770 stored elements and shape (82404, 2651)>,\n",
       " 'F': <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       " \twith 128452 stored elements and shape (82404, 6616)>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:27:31.059930Z",
     "iopub.status.busy": "2025-12-05T07:27:31.059549Z",
     "iopub.status.idle": "2025-12-05T07:27:42.782150Z",
     "shell.execute_reply": "2025-12-05T07:27:42.781424Z",
     "shell.execute_reply.started": "2025-12-05T07:27:31.059892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P loader ready: torch.Size([82404, 16858])\n",
      "C loader ready: torch.Size([82404, 2651])\n",
      "F loader ready: torch.Size([82404, 6616])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_norm, dtype=torch.float32)\n",
    "\n",
    "loaders = {}\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    # Convert sparse CSR → dense numpy → float tensor\n",
    "    y_dense = y_trains[aspect].toarray().astype('float32')\n",
    "    y_tensor = torch.tensor(y_dense, dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(X_train_tensor, y_tensor)\n",
    "\n",
    "    loaders[aspect] = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    print(aspect, \"loader ready:\", y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:27:44.479574Z",
     "iopub.status.busy": "2025-12-05T07:27:44.478977Z",
     "iopub.status.idle": "2025-12-05T07:27:44.485994Z",
     "shell.execute_reply": "2025-12-05T07:27:44.485207Z",
     "shell.execute_reply.started": "2025-12-05T07:27:44.479550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_one_model(model, loader, epochs=5, lr=1e-3, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)               # shape: (batch, num_labels)\n",
    "            loss = criterion(logits, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs}   Loss = {total_loss/len(loader):.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:27:48.800471Z",
     "iopub.status.busy": "2025-12-05T07:27:48.799779Z",
     "iopub.status.idle": "2025-12-05T07:28:57.530625Z",
     "shell.execute_reply": "2025-12-05T07:28:57.529907Z",
     "shell.execute_reply.started": "2025-12-05T07:27:48.800446Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training P ...\n",
      "Epoch 1/8   Loss = 0.0637\n",
      "Epoch 2/8   Loss = 0.0021\n",
      "Epoch 3/8   Loss = 0.0020\n",
      "Epoch 4/8   Loss = 0.0019\n",
      "Epoch 5/8   Loss = 0.0018\n",
      "Epoch 6/8   Loss = 0.0018\n",
      "Epoch 7/8   Loss = 0.0018\n",
      "Epoch 8/8   Loss = 0.0018\n",
      "\n",
      "Training C ...\n",
      "Epoch 1/8   Loss = 0.0668\n",
      "Epoch 2/8   Loss = 0.0047\n",
      "Epoch 3/8   Loss = 0.0045\n",
      "Epoch 4/8   Loss = 0.0044\n",
      "Epoch 5/8   Loss = 0.0043\n",
      "Epoch 6/8   Loss = 0.0043\n",
      "Epoch 7/8   Loss = 0.0042\n",
      "Epoch 8/8   Loss = 0.0042\n",
      "\n",
      "Training F ...\n",
      "Epoch 1/8   Loss = 0.0627\n",
      "Epoch 2/8   Loss = 0.0020\n",
      "Epoch 3/8   Loss = 0.0018\n",
      "Epoch 4/8   Loss = 0.0017\n",
      "Epoch 5/8   Loss = 0.0017\n",
      "Epoch 6/8   Loss = 0.0017\n",
      "Epoch 7/8   Loss = 0.0017\n",
      "Epoch 8/8   Loss = 0.0016\n"
     ]
    }
   ],
   "source": [
    "# Train 3 models\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "trained_models = dict()\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    print(\"\\nTraining\", aspect, \"...\")\n",
    "    trained_models[aspect] = train_one_model(\n",
    "        model=models[aspect],\n",
    "        loader=loaders[aspect],\n",
    "        epochs=8,\n",
    "        lr=1e-3,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Inference and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:28:58.701083Z",
     "iopub.status.busy": "2025-12-05T07:28:58.700385Z",
     "iopub.status.idle": "2025-12-05T07:29:53.454432Z",
     "shell.execute_reply": "2025-12-05T07:29:53.453794Z",
     "shell.execute_reply.started": "2025-12-05T07:28:58.701061Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on Test Set: 100%|██████████| 45/45 [00:54<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5000  # avoid memory overflow\n",
    "submission_list = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_ids), BATCH_SIZE), desc=\"Predicting on Test Set\"):\n",
    "    batch_entry_ids = test_ids[i : i + BATCH_SIZE]\n",
    "\n",
    "    # Slice features\n",
    "    X_batch = X_test_norm[i : i + BATCH_SIZE]\n",
    "    X_batch = torch.tensor(X_batch, dtype=torch.float32, device=device)\n",
    "\n",
    "    # For each ontology aspect (P, F, C)\n",
    "    for aspect, model in trained_models.items():\n",
    "        model.eval()\n",
    "\n",
    "        # Forward pass (logits → probabilities)\n",
    "        with torch.no_grad():\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()  # ndarray (batch, num_labels)\n",
    "\n",
    "        mlb = mlb_dict[aspect]  # MultiLabelBinarizer for this aspect\n",
    "\n",
    "        # Loop over proteins in the batch\n",
    "        for j, entry_id in enumerate(batch_entry_ids):\n",
    "            prob_vec = probs[j]\n",
    "\n",
    "            # threshold at 0.02\n",
    "            candidate_indices = np.where(prob_vec > 0.02)[0]\n",
    "\n",
    "            for idx in candidate_indices:\n",
    "                submission_list.append(\n",
    "                    (entry_id, mlb.classes_[idx], round(prob_vec[idx], 3))\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:29:55.952685Z",
     "iopub.status.busy": "2025-12-05T07:29:55.952002Z",
     "iopub.status.idle": "2025-12-05T07:30:03.640876Z",
     "shell.execute_reply": "2025-12-05T07:30:03.640205Z",
     "shell.execute_reply.started": "2025-12-05T07:29:55.952664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(\n",
    "    submission_list,\n",
    "    columns=['Protein Id', 'GO Term Id', 'Prediction']\n",
    ")\n",
    "\n",
    "submission_df = submission_df.sort_values(\n",
    "    by=['Protein Id', 'Prediction'],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# Limit 1500 predictions per protein\n",
    "final_submission_df = (\n",
    "    submission_df.groupby('Protein Id')\n",
    "    .head(1500)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "final_submission_df.to_csv('submission.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T07:30:05.761054Z",
     "iopub.status.busy": "2025-12-05T07:30:05.760788Z",
     "iopub.status.idle": "2025-12-05T07:30:05.779300Z",
     "shell.execute_reply": "2025-12-05T07:30:05.778580Z",
     "shell.execute_reply.started": "2025-12-05T07:30:05.761037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file 'submission.tsv' created successfully.\n",
      "Total predictions in final submission: 3,738,561\n",
      "Submission DataFrame Head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein Id</th>\n",
       "      <th>GO Term Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005515</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005829</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005634</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005886</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005737</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protein Id  GO Term Id  Prediction\n",
       "0  A0A017SE81  GO:0005515       0.371\n",
       "1  A0A017SE81  GO:0005829       0.122\n",
       "2  A0A017SE81  GO:0005634       0.113\n",
       "3  A0A017SE81  GO:0005886       0.104\n",
       "4  A0A017SE81  GO:0005737       0.078"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSubmission file 'submission.tsv' created successfully.\")\n",
    "print(f\"Total predictions in final submission: {len(final_submission_df):,}\")\n",
    "print(\"Submission DataFrame Head:\")\n",
    "display(final_submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14084779,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "datasetId": 8917191,
     "sourceId": 13991224,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
