{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAFA6-08-Model Improvement\n",
    "\n",
    "Improvement from CAFA6-07: 20 features to 320 features\n",
    "\n",
    "Future direction: Use model ensemble\n",
    "\n",
    "References:\n",
    "- https://www.kaggle.com/code/analyticaobscura/cafa-6-decoding-protein-mysteries\n",
    "- (ESM-2 embeddings 320 features) https://www.kaggle.com/code/dalloliogm/compute-protein-embeddings-with-esm2-esm-c/notebook\n",
    "- (MLP with ESM2) https://www.kaggle.com/code/jwang2025learning/cafa-6-function-prediction-using-prott5?scriptVersionId=282801093\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:23.393549Z",
     "iopub.status.busy": "2025-12-05T08:16:23.392946Z",
     "iopub.status.idle": "2025-12-05T08:16:26.918986Z",
     "shell.execute_reply": "2025-12-05T08:16:26.918117Z",
     "shell.execute_reply.started": "2025-12-05T08:16:23.393523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install biopython > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load CAFA6 files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:26.921178Z",
     "iopub.status.busy": "2025-12-05T08:16:26.920870Z",
     "iopub.status.idle": "2025-12-05T08:16:26.925007Z",
     "shell.execute_reply": "2025-12-05T08:16:26.924446Z",
     "shell.execute_reply.started": "2025-12-05T08:16:26.921154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO  # parse fasta file\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:26.926118Z",
     "iopub.status.busy": "2025-12-05T08:16:26.925899Z",
     "iopub.status.idle": "2025-12-05T08:16:26.939881Z",
     "shell.execute_reply": "2025-12-05T08:16:26.939360Z",
     "shell.execute_reply.started": "2025-12-05T08:16:26.926101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CAFA6 file paths\n",
    "TRAIN_TERMS = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\"\n",
    "TRAIN_SEQ = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta\"\n",
    "TRAIN_TAXONOMY = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_taxonomy.tsv\"\n",
    "TEST_SEQ = \"/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:26.940731Z",
     "iopub.status.busy": "2025-12-05T08:16:26.940547Z",
     "iopub.status.idle": "2025-12-05T08:16:28.310815Z",
     "shell.execute_reply": "2025-12-05T08:16:28.310099Z",
     "shell.execute_reply.started": "2025-12-05T08:16:26.940717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 82404 train and 224309 test sequences\n"
     ]
    }
   ],
   "source": [
    "# Dict {entryId, seq}\n",
    "train_sequences = {rec.id: str(rec.seq) for rec in SeqIO.parse(TRAIN_SEQ, 'fasta')}\n",
    "test_sequences  = {rec.id: str(rec.seq) for rec in SeqIO.parse(TEST_SEQ,  'fasta')}\n",
    "\n",
    "print(f'Loaded {len(train_sequences)} train and {len(test_sequences)} test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:28.312740Z",
     "iopub.status.busy": "2025-12-05T08:16:28.312477Z",
     "iopub.status.idle": "2025-12-05T08:16:28.366991Z",
     "shell.execute_reply": "2025-12-05T08:16:28.366248Z",
     "shell.execute_reply.started": "2025-12-05T08:16:28.312722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dict: ('sp|A0A0C5B5G6|MOTSC_HUMAN', 'MRWQEMGYIFYPRKLR')\n",
      "Test dict: ('A0A0C5B5G6', 'MRWQEMGYIFYPRKLR')\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dict:\", list(train_sequences.items())[0])\n",
    "print(\"Test dict:\", list(test_sequences.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:28.368712Z",
     "iopub.status.busy": "2025-12-05T08:16:28.368457Z",
     "iopub.status.idle": "2025-12-05T08:16:28.400983Z",
     "shell.execute_reply": "2025-12-05T08:16:28.400343Z",
     "shell.execute_reply.started": "2025-12-05T08:16:28.368694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ids = [i.split('|')[1] for i in train_sequences.keys()]\n",
    "test_ids = list(test_sequences.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature extraction\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:28.401959Z",
     "iopub.status.busy": "2025-12-05T08:16:28.401689Z",
     "iopub.status.idle": "2025-12-05T08:16:28.412179Z",
     "shell.execute_reply": "2025-12-05T08:16:28.411573Z",
     "shell.execute_reply.started": "2025-12-05T08:16:28.401936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Embeddings file paths\n",
    "ESM_EMBEDDINGS = \"/kaggle/input/esm2-t6-8m-ur50d-cafa6\"\n",
    "TRAIN_EMBEDDINGS = ESM_EMBEDDINGS + \"/protein_embeddings_train.npy\"\n",
    "TEST_EMBEDDINGS = ESM_EMBEDDINGS + \"/protein_embeddings_test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:28.413048Z",
     "iopub.status.busy": "2025-12-05T08:16:28.412856Z",
     "iopub.status.idle": "2025-12-05T08:16:28.566630Z",
     "shell.execute_reply": "2025-12-05T08:16:28.566002Z",
     "shell.execute_reply.started": "2025-12-05T08:16:28.413023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "X_train = np.load(TRAIN_EMBEDDINGS)\n",
    "X_test = np.load(TEST_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:28.567631Z",
     "iopub.status.busy": "2025-12-05T08:16:28.567370Z",
     "iopub.status.idle": "2025-12-05T08:16:28.571728Z",
     "shell.execute_reply": "2025-12-05T08:16:28.571122Z",
     "shell.execute_reply.started": "2025-12-05T08:16:28.567605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (82404, 320)\n",
      "X_test shape: (224309, 320)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:28.572706Z",
     "iopub.status.busy": "2025-12-05T08:16:28.572480Z",
     "iopub.status.idle": "2025-12-05T08:16:29.461518Z",
     "shell.execute_reply": "2025-12-05T08:16:29.460663Z",
     "shell.execute_reply.started": "2025-12-05T08:16:28.572691Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_norm shape: (82404, 320)\n",
      "X_test_norm shape: (224309, 320)\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "print(\"X_train_norm shape:\", X_train_norm.shape)\n",
    "print(\"X_test_norm shape:\", X_test_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Customized MLP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:29.462671Z",
     "iopub.status.busy": "2025-12-05T08:16:29.462407Z",
     "iopub.status.idle": "2025-12-05T08:16:29.467049Z",
     "shell.execute_reply": "2025-12-05T08:16:29.466309Z",
     "shell.execute_reply.started": "2025-12-05T08:16:29.462643Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:29.468273Z",
     "iopub.status.busy": "2025-12-05T08:16:29.467996Z",
     "iopub.status.idle": "2025-12-05T08:16:29.481620Z",
     "shell.execute_reply": "2025-12-05T08:16:29.480968Z",
     "shell.execute_reply.started": "2025-12-05T08:16:29.468230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(32, output_dim)   # no sigmoid here\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Label encoding\n",
    "\n",
    "We divide all labels into three subsets (one for MF, one for BP, and one for CC).\n",
    "-  As a result, for each sequence, we will have 3 vectors as follows using multi-hot encoding (i.e. simply one-hot for multi-classification problems)\n",
    "    - For MF: [0 1 0 1 ... 0] of length num_unique(MF_GO_temrs)\n",
    "    - For BP: [0 1 0 1 ... 0] of length num_unique(BP_GO_temrs)\n",
    "    - For CC: [0 1 0 1 ... 0] of length num_unique(CC_GO_temrs)\n",
    "- Then we will train three separate models for each ontology. We use three models to predict for a single example in the test set, and gather the predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:29.482612Z",
     "iopub.status.busy": "2025-12-05T08:16:29.482381Z",
     "iopub.status.idle": "2025-12-05T08:16:33.323981Z",
     "shell.execute_reply": "2025-12-05T08:16:33.323015Z",
     "shell.execute_reply.started": "2025-12-05T08:16:29.482592Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape for P ontology: (82404, 16858) \t\t Number of unique P terms: 16858\n",
      "y_train shape for C ontology: (82404, 2651) \t\t Number of unique C terms: 2651\n",
      "y_train shape for F ontology: (82404, 6616) \t\t Number of unique F terms: 6616\n"
     ]
    }
   ],
   "source": [
    "# Create three label sets\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "y_trains = dict()\n",
    "mlb_dict = dict()\n",
    "models = dict()\n",
    "\n",
    "train_terms_df = pd.read_csv(TRAIN_TERMS, sep=\"\\t\")\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    # Filter the train_terms_df based on aspect\n",
    "    ont_terms_df = train_terms_df[train_terms_df['aspect'] == aspect]\n",
    "\n",
    "    # Group the dataFrame based on the EntryID, turn all the GO terms to a list, finally turns this dataFrame to a dict {entryID: terms}\n",
    "    protein_terms = ont_terms_df.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "    # Create a list of labels for this aspect, if an entryID doesn't exist in this aspect, give it a []\n",
    "    # This ensures y_train is of shape (82404, ...)\n",
    "    labels = [protein_terms.get(entry_id, []) for entry_id in train_ids]\n",
    "\n",
    "    # Multi-hot encoding, use sparse representation\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    y_train = mlb.fit_transform(labels)\n",
    "    y_trains[aspect] = y_train\n",
    "    \n",
    "    print(f\"y_train shape for {aspect} ontology: {y_train.shape} \\t\\t Number of unique {aspect} terms: {y_train.shape[1]}\")\n",
    "\n",
    "    # Save to dict\n",
    "    mlb_dict[aspect] = mlb\n",
    "    model = MLPClassifier(input_dim=X_train.shape[1], output_dim=y_train.shape[1])\n",
    "    models[aspect] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:33.326732Z",
     "iopub.status.busy": "2025-12-05T08:16:33.326477Z",
     "iopub.status.idle": "2025-12-05T08:16:33.331878Z",
     "shell.execute_reply": "2025-12-05T08:16:33.331226Z",
     "shell.execute_reply.started": "2025-12-05T08:16:33.326715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': MLPClassifier(\n",
       "   (net): Sequential(\n",
       "     (0): Linear(in_features=320, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Dropout(p=0.2, inplace=False)\n",
       "     (7): Linear(in_features=32, out_features=16858, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'C': MLPClassifier(\n",
       "   (net): Sequential(\n",
       "     (0): Linear(in_features=320, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Dropout(p=0.2, inplace=False)\n",
       "     (7): Linear(in_features=32, out_features=2651, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'F': MLPClassifier(\n",
       "   (net): Sequential(\n",
       "     (0): Linear(in_features=320, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Dropout(p=0.2, inplace=False)\n",
       "     (7): Linear(in_features=32, out_features=6616, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:33.332848Z",
     "iopub.status.busy": "2025-12-05T08:16:33.332527Z",
     "iopub.status.idle": "2025-12-05T08:16:33.346940Z",
     "shell.execute_reply": "2025-12-05T08:16:33.346376Z",
     "shell.execute_reply.started": "2025-12-05T08:16:33.332825Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       " \twith 250805 stored elements and shape (82404, 16858)>,\n",
       " 'C': <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       " \twith 157770 stored elements and shape (82404, 2651)>,\n",
       " 'F': <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       " \twith 128452 stored elements and shape (82404, 6616)>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:33.347961Z",
     "iopub.status.busy": "2025-12-05T08:16:33.347674Z",
     "iopub.status.idle": "2025-12-05T08:16:45.524402Z",
     "shell.execute_reply": "2025-12-05T08:16:45.523635Z",
     "shell.execute_reply.started": "2025-12-05T08:16:33.347938Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P loader ready: torch.Size([82404, 16858])\n",
      "C loader ready: torch.Size([82404, 2651])\n",
      "F loader ready: torch.Size([82404, 6616])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_norm, dtype=torch.float32)\n",
    "\n",
    "loaders = {}\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    # Convert sparse CSR → dense numpy → float tensor\n",
    "    y_dense = y_trains[aspect].toarray().astype('float32')\n",
    "    y_tensor = torch.tensor(y_dense, dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(X_train_tensor, y_tensor)\n",
    "\n",
    "    loaders[aspect] = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    print(aspect, \"loader ready:\", y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:45.525517Z",
     "iopub.status.busy": "2025-12-05T08:16:45.525275Z",
     "iopub.status.idle": "2025-12-05T08:16:45.531206Z",
     "shell.execute_reply": "2025-12-05T08:16:45.530512Z",
     "shell.execute_reply.started": "2025-12-05T08:16:45.525500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_one_model(model, loader, epochs=5, lr=1e-3, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)               # shape: (batch, num_labels)\n",
    "            loss = criterion(logits, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs}   Loss = {total_loss/len(loader):.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:16:45.532328Z",
     "iopub.status.busy": "2025-12-05T08:16:45.532027Z",
     "iopub.status.idle": "2025-12-05T08:17:54.102218Z",
     "shell.execute_reply": "2025-12-05T08:17:54.101429Z",
     "shell.execute_reply.started": "2025-12-05T08:16:45.532308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training P ...\n",
      "Epoch 1/8   Loss = 0.0558\n",
      "Epoch 2/8   Loss = 0.0020\n",
      "Epoch 3/8   Loss = 0.0019\n",
      "Epoch 4/8   Loss = 0.0018\n",
      "Epoch 5/8   Loss = 0.0018\n",
      "Epoch 6/8   Loss = 0.0017\n",
      "Epoch 7/8   Loss = 0.0017\n",
      "Epoch 8/8   Loss = 0.0017\n",
      "\n",
      "Training C ...\n",
      "Epoch 1/8   Loss = 0.0537\n",
      "Epoch 2/8   Loss = 0.0045\n",
      "Epoch 3/8   Loss = 0.0043\n",
      "Epoch 4/8   Loss = 0.0042\n",
      "Epoch 5/8   Loss = 0.0041\n",
      "Epoch 6/8   Loss = 0.0040\n",
      "Epoch 7/8   Loss = 0.0039\n",
      "Epoch 8/8   Loss = 0.0039\n",
      "\n",
      "Training F ...\n",
      "Epoch 1/8   Loss = 0.0533\n",
      "Epoch 2/8   Loss = 0.0019\n",
      "Epoch 3/8   Loss = 0.0017\n",
      "Epoch 4/8   Loss = 0.0016\n",
      "Epoch 5/8   Loss = 0.0016\n",
      "Epoch 6/8   Loss = 0.0016\n",
      "Epoch 7/8   Loss = 0.0015\n",
      "Epoch 8/8   Loss = 0.0015\n"
     ]
    }
   ],
   "source": [
    "# Train 3 models\n",
    "trained_models = dict()\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    print(\"\\nTraining\", aspect, \"...\")\n",
    "    trained_models[aspect] = train_one_model(\n",
    "        model=models[aspect],\n",
    "        loader=loaders[aspect],\n",
    "        epochs=8,\n",
    "        lr=1e-3,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Inference and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:17:54.103511Z",
     "iopub.status.busy": "2025-12-05T08:17:54.103241Z",
     "iopub.status.idle": "2025-12-05T08:18:49.730879Z",
     "shell.execute_reply": "2025-12-05T08:18:49.730240Z",
     "shell.execute_reply.started": "2025-12-05T08:17:54.103493Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on Test Set: 100%|██████████| 45/45 [00:55<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5000  # avoid memory overflow\n",
    "submission_list = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_ids), BATCH_SIZE), desc=\"Predicting on Test Set\"):\n",
    "    batch_entry_ids = test_ids[i : i + BATCH_SIZE]\n",
    "\n",
    "    # Slice features\n",
    "    X_batch = X_test_norm[i : i + BATCH_SIZE]\n",
    "    X_batch = torch.tensor(X_batch, dtype=torch.float32, device=device)\n",
    "\n",
    "    # For each ontology aspect (P, F, C)\n",
    "    for aspect, model in trained_models.items():\n",
    "        model.eval()\n",
    "\n",
    "        # Forward pass (logits → probabilities)\n",
    "        with torch.no_grad():\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()  # ndarray (batch, num_labels)\n",
    "\n",
    "        mlb = mlb_dict[aspect]  # MultiLabelBinarizer for this aspect\n",
    "\n",
    "        # Loop over proteins in the batch\n",
    "        for j, entry_id in enumerate(batch_entry_ids):\n",
    "            prob_vec = probs[j]\n",
    "\n",
    "            # threshold at 0.02\n",
    "            candidate_indices = np.where(prob_vec > 0.02)[0]\n",
    "\n",
    "            for idx in candidate_indices:\n",
    "                submission_list.append(\n",
    "                    (entry_id, mlb.classes_[idx], round(prob_vec[idx], 3))\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:18:49.731900Z",
     "iopub.status.busy": "2025-12-05T08:18:49.731648Z",
     "iopub.status.idle": "2025-12-05T08:18:58.572721Z",
     "shell.execute_reply": "2025-12-05T08:18:58.571769Z",
     "shell.execute_reply.started": "2025-12-05T08:18:49.731875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(\n",
    "    submission_list,\n",
    "    columns=['Protein Id', 'GO Term Id', 'Prediction']\n",
    ")\n",
    "\n",
    "submission_df = submission_df.sort_values(\n",
    "    by=['Protein Id', 'Prediction'],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# Limit 1500 predictions per protein\n",
    "final_submission_df = (\n",
    "    submission_df.groupby('Protein Id')\n",
    "    .head(1500)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "final_submission_df.to_csv('submission.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:18:58.574200Z",
     "iopub.status.busy": "2025-12-05T08:18:58.573916Z",
     "iopub.status.idle": "2025-12-05T08:18:58.583077Z",
     "shell.execute_reply": "2025-12-05T08:18:58.582402Z",
     "shell.execute_reply.started": "2025-12-05T08:18:58.574176Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file 'submission.tsv' created successfully.\n",
      "Total predictions in final submission: 4,164,029\n",
      "Submission DataFrame Head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein Id</th>\n",
       "      <th>GO Term Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005515</td>\n",
       "      <td>0.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005886</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005829</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005739</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005783</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protein Id  GO Term Id  Prediction\n",
       "0  A0A017SE81  GO:0005515       0.257\n",
       "1  A0A017SE81  GO:0005886       0.183\n",
       "2  A0A017SE81  GO:0005829       0.092\n",
       "3  A0A017SE81  GO:0005739       0.090\n",
       "4  A0A017SE81  GO:0005783       0.050"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSubmission file 'submission.tsv' created successfully.\")\n",
    "print(f\"Total predictions in final submission: {len(final_submission_df):,}\")\n",
    "print(\"Submission DataFrame Head:\")\n",
    "display(final_submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14084779,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "datasetId": 8917191,
     "sourceId": 13991224,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
