{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAFA6-11-Model Improvement\n",
    "\n",
    "Improvement from CAFA6-08: use model ensemble (LogisticRegression + MLP)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:05:48.370573Z",
     "iopub.status.busy": "2025-12-07T14:05:48.370257Z",
     "iopub.status.idle": "2025-12-07T14:05:55.368491Z",
     "shell.execute_reply": "2025-12-07T14:05:55.367389Z",
     "shell.execute_reply.started": "2025-12-07T14:05:48.370549Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load CAFA6 files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:05:59.747694Z",
     "iopub.status.busy": "2025-12-07T14:05:59.746625Z",
     "iopub.status.idle": "2025-12-07T14:05:59.752591Z",
     "shell.execute_reply": "2025-12-07T14:05:59.751357Z",
     "shell.execute_reply.started": "2025-12-07T14:05:59.747651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CAFA6 file paths\n",
    "TRAIN_TERMS = \"data/Train/train_terms.tsv\"\n",
    "TRAIN_SEQ = \"data/Train/train_sequences.fasta\"\n",
    "TEST_SEQ = \"data/Test/testsuperset.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:06:00.469627Z",
     "iopub.status.busy": "2025-12-07T14:06:00.469309Z",
     "iopub.status.idle": "2025-12-07T14:06:03.082965Z",
     "shell.execute_reply": "2025-12-07T14:06:03.082009Z",
     "shell.execute_reply.started": "2025-12-07T14:06:00.469602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 82404 train and 224309 test sequences\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Dict {entryId, seq}\n",
    "train_sequences = {rec.id: str(rec.seq) for rec in SeqIO.parse(TRAIN_SEQ, 'fasta')}\n",
    "test_sequences  = {rec.id: str(rec.seq) for rec in SeqIO.parse(TEST_SEQ,  'fasta')}\n",
    "\n",
    "print(f'Loaded {len(train_sequences)} train and {len(test_sequences)} test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:06:03.084947Z",
     "iopub.status.busy": "2025-12-07T14:06:03.084459Z",
     "iopub.status.idle": "2025-12-07T14:06:03.179943Z",
     "shell.execute_reply": "2025-12-07T14:06:03.177880Z",
     "shell.execute_reply.started": "2025-12-07T14:06:03.084918Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dict: ('sp|A0A0C5B5G6|MOTSC_HUMAN', 'MRWQEMGYIFYPRKLR')\n",
      "Test dict: ('A0A0C5B5G6', 'MRWQEMGYIFYPRKLR')\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dict:\", list(train_sequences.items())[0])\n",
    "print(\"Test dict:\", list(test_sequences.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:06:03.181344Z",
     "iopub.status.busy": "2025-12-07T14:06:03.180773Z",
     "iopub.status.idle": "2025-12-07T14:06:03.219653Z",
     "shell.execute_reply": "2025-12-07T14:06:03.218581Z",
     "shell.execute_reply.started": "2025-12-07T14:06:03.181310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ids = [i.split('|')[1] for i in train_sequences.keys()]\n",
    "test_ids = list(test_sequences.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature extraction\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:06:38.013840Z",
     "iopub.status.busy": "2025-12-07T14:06:38.012915Z",
     "iopub.status.idle": "2025-12-07T14:06:38.018060Z",
     "shell.execute_reply": "2025-12-07T14:06:38.016982Z",
     "shell.execute_reply.started": "2025-12-07T14:06:38.013808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Embeddings file paths\n",
    "ESM_EMBEDDINGS = \"ESM2\"\n",
    "TRAIN_EMBEDDINGS = ESM_EMBEDDINGS + \"/protein_embeddings_train.npy\"\n",
    "TEST_EMBEDDINGS = ESM_EMBEDDINGS + \"/protein_embeddings_test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:06:38.558763Z",
     "iopub.status.busy": "2025-12-07T14:06:38.558436Z",
     "iopub.status.idle": "2025-12-07T14:06:40.296943Z",
     "shell.execute_reply": "2025-12-07T14:06:40.296106Z",
     "shell.execute_reply.started": "2025-12-07T14:06:38.558738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.load(TRAIN_EMBEDDINGS)\n",
    "X_test = np.load(TEST_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:06:41.016593Z",
     "iopub.status.busy": "2025-12-07T14:06:41.016299Z",
     "iopub.status.idle": "2025-12-07T14:06:41.021378Z",
     "shell.execute_reply": "2025-12-07T14:06:41.020427Z",
     "shell.execute_reply.started": "2025-12-07T14:06:41.016570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (82404, 320)\n",
      "X_test shape: (224309, 320)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:06:44.860079Z",
     "iopub.status.busy": "2025-12-07T14:06:44.858997Z",
     "iopub.status.idle": "2025-12-07T14:06:48.344960Z",
     "shell.execute_reply": "2025-12-07T14:06:48.344083Z",
     "shell.execute_reply.started": "2025-12-07T14:06:44.860049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100, random_state=42)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced  = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:06:48.347080Z",
     "iopub.status.busy": "2025-12-07T14:06:48.346443Z",
     "iopub.status.idle": "2025-12-07T14:06:48.351838Z",
     "shell.execute_reply": "2025-12-07T14:06:48.350765Z",
     "shell.execute_reply.started": "2025-12-07T14:06:48.347049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_reduced shape: (82404, 100)\n",
      "X_test_reduced shape: (224309, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_reduced shape:\", X_train_reduced.shape)\n",
    "print(\"X_test_reduced shape:\", X_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:09:04.298796Z",
     "iopub.status.busy": "2025-12-07T14:09:04.298466Z",
     "iopub.status.idle": "2025-12-07T14:09:05.991335Z",
     "shell.execute_reply": "2025-12-07T14:09:05.990481Z",
     "shell.execute_reply.started": "2025-12-07T14:09:04.298777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_norm shape (MLP): (82404, 320)\n",
      "X_test_norm shape (MLP): (224309, 320)\n",
      "X_train_norm shape (Logistic): (82404, 100)\n",
      "X_test_norm shape (Logistic): (224309, 100)\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_dict = {\n",
    "    'MLP': {},\n",
    "    'Logistic': {}\n",
    "}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "print(\"X_train_norm shape (MLP):\", X_train_norm.shape)\n",
    "print(\"X_test_norm shape (MLP):\", X_test_norm.shape)\n",
    "\n",
    "X_train_dict['MLP']['X_train'] = X_train_norm\n",
    "X_train_dict['MLP']['X_test'] = X_test_norm\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train_reduced)\n",
    "X_test_norm = scaler.transform(X_test_reduced)\n",
    "print(\"X_train_norm shape (Logistic):\", X_train_norm.shape)\n",
    "print(\"X_test_norm shape (Logistic):\", X_test_norm.shape)\n",
    "\n",
    "X_train_dict['Logistic']['X_train'] = X_train_norm\n",
    "X_train_dict['Logistic']['X_test'] = X_test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Customized MLP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:10:17.015802Z",
     "iopub.status.busy": "2025-12-07T14:10:17.015468Z",
     "iopub.status.idle": "2025-12-07T14:10:18.907211Z",
     "shell.execute_reply": "2025-12-07T14:10:18.906269Z",
     "shell.execute_reply.started": "2025-12-07T14:10:17.015779Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:10:18.909124Z",
     "iopub.status.busy": "2025-12-07T14:10:18.908593Z",
     "iopub.status.idle": "2025-12-07T14:10:18.915454Z",
     "shell.execute_reply": "2025-12-07T14:10:18.914242Z",
     "shell.execute_reply.started": "2025-12-07T14:10:18.909070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(1024, output_dim)  # logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Label encoding + MLP training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:12:17.190562Z",
     "iopub.status.busy": "2025-12-07T14:12:17.190175Z",
     "iopub.status.idle": "2025-12-07T14:12:22.313845Z",
     "shell.execute_reply": "2025-12-07T14:12:22.312982Z",
     "shell.execute_reply.started": "2025-12-07T14:12:17.190538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape for P ontology: (82404, 16858) \t\t Number of unique P terms: 16858\n",
      "y_train shape for C ontology: (82404, 2651) \t\t Number of unique C terms: 2651\n",
      "y_train shape for F ontology: (82404, 6616) \t\t Number of unique F terms: 6616\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "mlp_y_trains = dict()\n",
    "mlp_mlb_dict = dict()\n",
    "mlp_models = dict()\n",
    "\n",
    "train_terms_df = pd.read_csv(TRAIN_TERMS, sep=\"\\t\")\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    # Filter the train_terms_df based on aspect\n",
    "    ont_terms_df = train_terms_df[train_terms_df['aspect'] == aspect]\n",
    "\n",
    "    # Group the dataFrame based on the EntryID, turn all the GO terms to a list, finally turns this dataFrame to a dict {entryID: terms}\n",
    "    protein_terms = ont_terms_df.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "    # Create a list of labels for this aspect, if an entryID doesn't exist in this aspect, give it a []\n",
    "    # This ensures y_train is of shape (82404, ...)\n",
    "    labels = [protein_terms.get(entry_id, []) for entry_id in train_ids]\n",
    "\n",
    "    # Multi-hot encoding, use sparse representation\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    y_train = mlb.fit_transform(labels)\n",
    "    mlp_y_trains[aspect] = y_train\n",
    "    \n",
    "    print(f\"y_train shape for {aspect} ontology: {y_train.shape} \\t\\t Number of unique {aspect} terms: {y_train.shape[1]}\")\n",
    "\n",
    "    # Save to dict\n",
    "    mlp_mlb_dict[aspect] = mlb\n",
    "    model = MLPClassifier(input_dim=X_train.shape[1], output_dim=y_train.shape[1])\n",
    "    mlp_models[aspect] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:12:23.830884Z",
     "iopub.status.busy": "2025-12-07T14:12:23.830558Z",
     "iopub.status.idle": "2025-12-07T14:12:23.838789Z",
     "shell.execute_reply": "2025-12-07T14:12:23.837777Z",
     "shell.execute_reply.started": "2025-12-07T14:12:23.830862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': MLPClassifier(\n",
       "   (net): Sequential(\n",
       "     (0): Linear(in_features=320, out_features=2048, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (7): Dropout(p=0.25, inplace=False)\n",
       "     (8): Linear(in_features=1024, out_features=16858, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'C': MLPClassifier(\n",
       "   (net): Sequential(\n",
       "     (0): Linear(in_features=320, out_features=2048, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (7): Dropout(p=0.25, inplace=False)\n",
       "     (8): Linear(in_features=1024, out_features=2651, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'F': MLPClassifier(\n",
       "   (net): Sequential(\n",
       "     (0): Linear(in_features=320, out_features=2048, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (7): Dropout(p=0.25, inplace=False)\n",
       "     (8): Linear(in_features=1024, out_features=6616, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:12:27.318633Z",
     "iopub.status.busy": "2025-12-07T14:12:27.317808Z",
     "iopub.status.idle": "2025-12-07T14:12:27.324532Z",
     "shell.execute_reply": "2025-12-07T14:12:27.323676Z",
     "shell.execute_reply.started": "2025-12-07T14:12:27.318606Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       " \twith 250805 stored elements and shape (82404, 16858)>,\n",
       " 'C': <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       " \twith 157770 stored elements and shape (82404, 2651)>,\n",
       " 'F': <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       " \twith 128452 stored elements and shape (82404, 6616)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_y_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:13:06.342202Z",
     "iopub.status.busy": "2025-12-07T14:13:06.341884Z",
     "iopub.status.idle": "2025-12-07T14:13:20.948595Z",
     "shell.execute_reply": "2025-12-07T14:13:20.947692Z",
     "shell.execute_reply.started": "2025-12-07T14:13:06.342183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P loader ready: torch.Size([82404, 16858])\n",
      "C loader ready: torch.Size([82404, 2651])\n",
      "F loader ready: torch.Size([82404, 6616])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_dict['MLP']['X_train'], dtype=torch.float32)\n",
    "\n",
    "loaders = {}\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    # Convert sparse CSR → dense numpy → float tensor\n",
    "    y_dense = mlp_y_trains[aspect].toarray().astype('float32')\n",
    "    y_tensor = torch.tensor(y_dense, dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(X_train_tensor, y_tensor)\n",
    "\n",
    "    loaders[aspect] = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    print(aspect, \"loader ready:\", y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:24:52.300469Z",
     "iopub.status.busy": "2025-12-07T14:24:52.299906Z",
     "iopub.status.idle": "2025-12-07T14:24:52.308909Z",
     "shell.execute_reply": "2025-12-07T14:24:52.307880Z",
     "shell.execute_reply.started": "2025-12-07T14:24:52.300440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_one_model(model, loader, epochs=5, lr=1e-3, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)               # shape: (batch, num_labels)\n",
    "            loss = criterion(logits, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs}   Loss = {total_loss/len(loader):.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:24:52.545774Z",
     "iopub.status.busy": "2025-12-07T14:24:52.545451Z",
     "iopub.status.idle": "2025-12-07T14:24:56.989580Z",
     "shell.execute_reply": "2025-12-07T14:24:56.988202Z",
     "shell.execute_reply.started": "2025-12-07T14:24:52.545751Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training P ...\n",
      "Epoch 1/8   Loss = 0.0645\n",
      "Epoch 2/8   Loss = 0.0017\n",
      "Epoch 3/8   Loss = 0.0015\n",
      "Epoch 4/8   Loss = 0.0015\n",
      "Epoch 5/8   Loss = 0.0015\n",
      "Epoch 6/8   Loss = 0.0014\n",
      "Epoch 7/8   Loss = 0.0014\n",
      "Epoch 8/8   Loss = 0.0013\n",
      "\n",
      "Training C ...\n",
      "Epoch 1/8   Loss = 0.0680\n",
      "Epoch 2/8   Loss = 0.0038\n",
      "Epoch 3/8   Loss = 0.0035\n",
      "Epoch 4/8   Loss = 0.0034\n",
      "Epoch 5/8   Loss = 0.0033\n",
      "Epoch 6/8   Loss = 0.0032\n",
      "Epoch 7/8   Loss = 0.0031\n",
      "Epoch 8/8   Loss = 0.0031\n",
      "\n",
      "Training F ...\n",
      "Epoch 1/8   Loss = 0.0659\n",
      "Epoch 2/8   Loss = 0.0016\n",
      "Epoch 3/8   Loss = 0.0014\n",
      "Epoch 4/8   Loss = 0.0013\n",
      "Epoch 5/8   Loss = 0.0012\n",
      "Epoch 6/8   Loss = 0.0012\n",
      "Epoch 7/8   Loss = 0.0011\n",
      "Epoch 8/8   Loss = 0.0011\n"
     ]
    }
   ],
   "source": [
    "# Train 3 models\n",
    "trained_mlp_models = dict()\n",
    "\n",
    "for aspect in ['P', 'C', 'F']:\n",
    "    print(\"\\nTraining\", aspect, \"...\")\n",
    "    trained_mlp_models[aspect] = train_one_model(\n",
    "        model=mlp_models[aspect],\n",
    "        loader=loaders[aspect],\n",
    "        epochs=8,\n",
    "        lr=1e-3,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Label encoding + Logistic Regression model training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:25:19.119293Z",
     "iopub.status.busy": "2025-12-07T14:25:19.118539Z",
     "iopub.status.idle": "2025-12-07T14:25:27.429516Z",
     "shell.execute_reply": "2025-12-07T14:25:27.428234Z",
     "shell.execute_reply.started": "2025-12-07T14:25:19.119265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape for P ontology: (82404, 16858) \t\t Number of unique P terms: 16858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression:  33%|███▎      | 1/3 [38:01<1:16:02, 2281.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for P trained successfully.\n",
      "y_train shape for C ontology: (82404, 2651) \t\t Number of unique C terms: 2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression:  67%|██████▋   | 2/3 [44:01<19:11, 1151.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for C trained successfully.\n",
      "y_train shape for F ontology: (82404, 6616) \t\t Number of unique F terms: 6616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression: 100%|██████████| 3/3 [58:57<00:00, 1179.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for F trained successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "logistic_mlb_dict = dict()\n",
    "logistic_models = dict()\n",
    "\n",
    "for aspect in tqdm(['P', 'C', 'F'], desc=\"Training Logistic Regression\"):\n",
    "    # Filter the train_terms_df based on aspect\n",
    "    ont_terms_df = train_terms_df[train_terms_df['aspect'] == aspect]\n",
    "\n",
    "    # Group the dataFrame based on the EntryID, turn all the GO terms to a list, finally turns this dataFrame to a dict {entryID: terms}\n",
    "    protein_terms = ont_terms_df.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "    # Create a list of labels for this aspect, if an entryID doesn't exist in this aspect, give it a []\n",
    "    # This ensures y_train is of shape (82404, ...)\n",
    "    labels = [protein_terms.get(entry_id, []) for entry_id in train_ids]\n",
    "\n",
    "    # Multi-hot encoding, use sparse representation\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    y_train = mlb.fit_transform(labels)\n",
    "    \n",
    "    print(f\"y_train shape for {aspect} ontology: {y_train.shape} \\t\\t Number of unique {aspect} terms: {y_train.shape[1]}\")\n",
    "\n",
    "    # Save to dict\n",
    "    logistic_mlb_dict[aspect] = mlb\n",
    "    model = OneVsRestClassifier(LogisticRegression(max_iter=600, solver='lbfgs', C=0.5, random_state=42), n_jobs=-1)\n",
    "    model.fit(X_train_dict['Logistic']['X_train'], y_train)\n",
    "    logistic_models[aspect] = model\n",
    "    print(f\"Model for {aspect} trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Inference and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:25:30.538991Z",
     "iopub.status.busy": "2025-12-07T14:25:30.538588Z",
     "iopub.status.idle": "2025-12-07T14:25:30.711174Z",
     "shell.execute_reply": "2025-12-07T14:25:30.710297Z",
     "shell.execute_reply.started": "2025-12-07T14:25:30.538965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with MLP: 100%|██████████| 45/45 [01:27<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5000  # avoid memory overflow\n",
    "mlp_submission_list = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_ids), BATCH_SIZE), desc=\"Predicting with MLP\"):\n",
    "    batch_entry_ids = test_ids[i : i + BATCH_SIZE]\n",
    "\n",
    "    # Slice features\n",
    "    X_batch = X_train_dict['MLP']['X_test'][i : i + BATCH_SIZE]\n",
    "    X_batch = torch.tensor(X_batch, dtype=torch.float32, device=device)\n",
    "\n",
    "    # For each ontology aspect (P, F, C)\n",
    "    for aspect, model in trained_mlp_models.items():\n",
    "        model.eval()\n",
    "\n",
    "        # Forward pass (logits → probabilities)\n",
    "        with torch.no_grad():\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()  # ndarray (batch, num_labels)\n",
    "\n",
    "        mlb = mlp_mlb_dict[aspect]  # MultiLabelBinarizer for this aspect\n",
    "\n",
    "        # Loop over proteins in the batch\n",
    "        for j, entry_id in enumerate(batch_entry_ids):\n",
    "            prob_vec = probs[j]\n",
    "\n",
    "            # threshold at 0.02\n",
    "            candidate_indices = np.where(prob_vec > 0.02)[0]\n",
    "\n",
    "            for idx in candidate_indices:\n",
    "                mlp_submission_list.append(\n",
    "                    (entry_id, mlb.classes_[idx], round(prob_vec[idx], 3))\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:25:32.508367Z",
     "iopub.status.busy": "2025-12-07T14:25:32.508059Z",
     "iopub.status.idle": "2025-12-07T14:25:32.513511Z",
     "shell.execute_reply": "2025-12-07T14:25:32.512555Z",
     "shell.execute_reply.started": "2025-12-07T14:25:32.508340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,664,932\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(mlp_submission_list):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:26:05.713624Z",
     "iopub.status.busy": "2025-12-07T14:26:05.713315Z",
     "iopub.status.idle": "2025-12-07T14:26:05.729856Z",
     "shell.execute_reply": "2025-12-07T14:26:05.728834Z",
     "shell.execute_reply.started": "2025-12-07T14:26:05.713601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with Logistic Regression: 100%|██████████| 45/45 [42:02<00:00, 56.05s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5000  # avoid memory overflow\n",
    "logistic_submission_list = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_ids), BATCH_SIZE), desc=\"Predicting with Logistic Regression\"):\n",
    "    batch_entry_ids = test_ids[i : i + BATCH_SIZE]\n",
    "\n",
    "    # Slice PCA-reduced features\n",
    "    X_batch = X_train_dict['Logistic']['X_test'][i : i + BATCH_SIZE]\n",
    "\n",
    "    for aspect, model in logistic_models.items():\n",
    "        mlb = logistic_mlb_dict[aspect]\n",
    "        y_pred_proba = model.predict_proba(X_batch)\n",
    "\n",
    "        for j, entry_id in enumerate(batch_entry_ids):\n",
    "            probs = y_pred_proba[j]\n",
    "            candidate_indices = np.where(probs > 0.02)[0]\n",
    "\n",
    "            for idx in candidate_indices:\n",
    "                logistic_submission_list.append((entry_id, mlb.classes_[idx], round(probs[idx], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:26:07.916754Z",
     "iopub.status.busy": "2025-12-07T14:26:07.916444Z",
     "iopub.status.idle": "2025-12-07T14:26:07.921478Z",
     "shell.execute_reply": "2025-12-07T14:26:07.920522Z",
     "shell.execute_reply.started": "2025-12-07T14:26:07.916732Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,084,372\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(logistic_submission_list):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T14:26:09.831767Z",
     "iopub.status.busy": "2025-12-07T14:26:09.831440Z",
     "iopub.status.idle": "2025-12-07T14:26:09.850161Z",
     "shell.execute_reply": "2025-12-07T14:26:09.848769Z",
     "shell.execute_reply.started": "2025-12-07T14:26:09.831741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging MLP: 100%|██████████| 5664932/5664932 [00:10<00:00, 554462.46it/s] \n",
      "Merging Logistic: 100%|██████████| 8084372/8084372 [00:09<00:00, 840471.18it/s] \n",
      "Weighted averaging: 100%|██████████| 10196964/10196964 [00:34<00:00, 299548.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Weighted ensemble. MLP: w, Logistic: (1-w).\n",
    "# Weight computed from accuracy: 0.262 / (0.262 + 0.230) = 0.53\n",
    "w = 0.53\n",
    "\n",
    "merged_dict = defaultdict(lambda: [None, None])  \n",
    "# [mlp_score, logistic_score]\n",
    "\n",
    "# Add MLP predictions\n",
    "for entry_id, go_term, score in tqdm(mlp_submission_list, desc=\"Merging MLP\"):\n",
    "    merged_dict[(entry_id, go_term)][0] = score\n",
    "\n",
    "# Add Logistic predictions\n",
    "for entry_id, go_term, score in tqdm(logistic_submission_list, desc=\"Merging Logistic\"):\n",
    "    merged_dict[(entry_id, go_term)][1] = score\n",
    "\n",
    "# Final weighted merge\n",
    "submission_list = []\n",
    "\n",
    "for (entry_id, go_term), (mlp_score, log_score) in tqdm(merged_dict.items(), desc=\"Weighted averaging\"):\n",
    "    # treat missing values as 0 if they don't appear in one of the lists\n",
    "    mlp_score = mlp_score if mlp_score is not None else 0.0\n",
    "    log_score = log_score if log_score is not None else 0.0\n",
    "\n",
    "    final_score = w * mlp_score + (1 - w) * log_score\n",
    "    submission_list.append((entry_id, go_term, round(final_score, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T02:31:40.861885Z",
     "iopub.status.busy": "2025-12-07T02:31:40.861619Z",
     "iopub.status.idle": "2025-12-07T02:31:53.050001Z",
     "shell.execute_reply": "2025-12-07T02:31:53.049213Z",
     "shell.execute_reply.started": "2025-12-07T02:31:40.861863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(\n",
    "    submission_list,\n",
    "    columns=['Protein Id', 'GO Term Id', 'Prediction']\n",
    ")\n",
    "\n",
    "submission_df = submission_df.sort_values(\n",
    "    by=['Protein Id', 'Prediction'],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# Limit 1500 predictions per protein\n",
    "final_submission_df = (\n",
    "    submission_df.groupby('Protein Id')\n",
    "    .head(1500)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "final_submission_df.to_csv('submission.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T02:31:53.051321Z",
     "iopub.status.busy": "2025-12-07T02:31:53.050982Z",
     "iopub.status.idle": "2025-12-07T02:31:53.062249Z",
     "shell.execute_reply": "2025-12-07T02:31:53.06147Z",
     "shell.execute_reply.started": "2025-12-07T02:31:53.051292Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file 'submission.tsv' created successfully.\n",
      "Total predictions in final submission: 10,196,836\n",
      "Submission DataFrame Head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein Id</th>\n",
       "      <th>GO Term Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005515</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0008209</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0047044</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005886</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0004303</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protein Id  GO Term Id  Prediction\n",
       "0  A0A017SE81  GO:0005515       0.160\n",
       "1  A0A017SE81  GO:0008209       0.149\n",
       "2  A0A017SE81  GO:0047044       0.143\n",
       "3  A0A017SE81  GO:0005886       0.126\n",
       "4  A0A017SE81  GO:0004303       0.111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSubmission file 'submission.tsv' created successfully.\")\n",
    "print(f\"Total predictions in final submission: {len(final_submission_df):,}\")\n",
    "print(\"Submission DataFrame Head:\")\n",
    "display(final_submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14084779,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 14766799,
     "datasetId": 8917191,
     "sourceId": 13991224,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
